{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VN9CHgR9abcE"
      },
      "source": [
        "# PROYECTO 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud6KEYvHabcH"
      },
      "source": [
        "Descripción proyecto"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "43IO1yccabcI"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install numpy --upgrade\n",
        "%pip install mahotas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5ghE_GnuabcJ",
        "outputId": "cc65cb88-c78d-4de1-f395-a7e92b743d9e"
      },
      "outputs": [],
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Procesamiento de imagenes\n",
        "import cv2\n",
        "\n",
        "# Visualizacion\n",
        "from   tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extraccion/seleccion de caracteristicas, clasificacion, evaluacion\n",
        "from   balu3.fx.geo    import fourierdes, hugeo, flusser, gupta,basicgeo # caracteristicas geometricas?\n",
        "from   balu3.fx.chr    import lbp, haralick, gabor, hog\n",
        "from   balu3.ft.norm   import minmax\n",
        "from   balu3.fs.sel    import jfisher,sfs,clean, exsearch\n",
        "from   balu3.io.misc   import imageload\n",
        "from   balu3.cl.basics import ClassifierKNN\n",
        "from   balu3.ft.trans  import pca\n",
        "from scipy.stats import mode\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.measure import moments\n",
        "from skimage.feature import graycomatrix, daisy, graycoprops\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, RFE, RFECV, mutual_info_classif ## fisher_score, \n",
        "from sklearn.cross_decomposition import PLSRegression \n",
        "\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as mlxsfs\n",
        "from mahotas.features import zernike_moments"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'lbp': 531, 'haralick': 24, 'gabor': 67, 'hog': 9, 'zernike': 25, 'glcm': 4, 'daisy': 768}\n"
          ]
        }
      ],
      "source": [
        "IMG_WIDTH = IMG_HEIGHT = (400 // 1.4) * 2\n",
        "\n",
        "# LBP\n",
        "LBP_HDIV = LBP_VDIV = 3\n",
        "LBP_BINS = 59\n",
        "\n",
        "# Haralick\n",
        "HAR_DISTANCE = 3\n",
        "HAR_SIZE = 24\n",
        "\n",
        "# Gabor\n",
        "GAB_ROTATIONS = 8\n",
        "GAB_DILATATIONS = 8\n",
        "\n",
        "# HOG\n",
        "HOG_ORIENTATIONS = 9\n",
        "\n",
        "# Zernike\n",
        "ZER_RADIUS = 30\n",
        "ZER_DEGREE = 8\n",
        "ZER_SIZE = 25\n",
        "\n",
        "# GLCM\n",
        "GLCM_DISTANCES = 1\n",
        "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "GLCM_LEVELS = 4\n",
        "\n",
        "GLCM_SIZE = GLCM_LEVELS\n",
        "\n",
        "# Daisy\n",
        "DAISY_RINGS = 1\n",
        "DAISY_STEP = 150\n",
        "DAISY_RADIUS = 50\n",
        "DAISY_ORIENTATIONS = 8\n",
        "DAISY_HISTOGRAMS = 5\n",
        "DAISY_P = math.ceil((IMG_WIDTH - DAISY_RADIUS * 2) / DAISY_STEP) \n",
        "DAISY_Q = math.ceil((IMG_HEIGHT - DAISY_RADIUS * 2) / DAISY_STEP)\n",
        "DAISY_R = (DAISY_RINGS * DAISY_HISTOGRAMS + 1) * DAISY_ORIENTATIONS\n",
        "\n",
        "# Fetaures\n",
        "features_per_function = {\n",
        "    \"lbp\": LBP_HDIV * LBP_VDIV * LBP_BINS,\n",
        "    \"haralick\": HAR_SIZE,\n",
        "    \"gabor\": GAB_ROTATIONS * GAB_DILATATIONS + 3,\n",
        "    \"hog\": HOG_ORIENTATIONS,\n",
        "    \"zernike\": ZER_SIZE,\n",
        "    \"glcm\": GLCM_SIZE,\n",
        "    \"daisy\": DAISY_P * DAISY_Q * DAISY_R\n",
        "}\n",
        "print(features_per_function)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros Selección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SFS\n",
        "N_SFS = 100\n",
        "\n",
        "# Exhaustive\n",
        "N_EX = 5\n",
        "\n",
        "# RFECV\n",
        "RFECV_STEP = 1\n",
        "RFECV_CV = 5\n",
        "\n",
        "# SBS\n",
        "N_SBS = 100\n",
        "SBS_VERBOSE = 2\n",
        "SBS_CV = 100\n",
        "\n",
        "# PCA\n",
        "N_PCA = 100\n",
        "\n",
        "# ICA\n",
        "N_ICA = 100\n",
        "ICA_RANDOM_STATE = 0\n",
        "\n",
        "# PLSR\n",
        "N_PLSR = 100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfP13LKRabcK"
      },
      "source": [
        "### Funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Si6OrksrabcK"
      },
      "outputs": [],
      "source": [
        "LBP_HDIV = LBP_VDIV = 3\n",
        "DAISY_RINGS = 1\n",
        "\n",
        "\n",
        "def extract_features(color_mode, dataset_type, feature_type):\n",
        "    # Cargar rutas de imágenes y etiquetas según el dataset_type\n",
        "    # ...\n",
        "    K = 90   # <= NUMERO DE CLASES\n",
        "\n",
        "    if dataset_type == 'train':\n",
        "        fpath = \"G00\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 12   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12)\n",
        "\n",
        "    elif dataset_type == 'test':\n",
        "        fpath = \"G01\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 4   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12, 16)\n",
        "\n",
        "    elif dataset_type == 'test2':\n",
        "        fpath = \"G02\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 4   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(16, 20)\n",
        "\n",
        "    dig_clase = 3     # <= NÚMERO DE DÍGITOS POR CLASE\n",
        "    dig_img = 3     # <= NÚMERO DE DÍGITOS POR NÚMERO DE IMAGEN\n",
        "    prefix = \"ID\"     # <= PREFIJO DEL NOMBRE DEL ARCHIVO DE LA IMAGEN\n",
        "    imprefix = fpath + '/' + prefix\n",
        "\n",
        "    # ground truth (clasificacion ideal)\n",
        "    y = np.zeros((K*N), 'int')\n",
        "    features = np.zeros((K*N, features_per_function[feature_type]))\n",
        "\n",
        "    t = 0\n",
        "    for j in tqdm(range(K)):                  # para cada clase\n",
        "        for i in n:                # para cada imagen de la clase\n",
        "            # Lectura de la imagen\n",
        "            clase = j+1\n",
        "            num_img = i+1\n",
        "            img = imageload(imprefix, clase, dig_clase,\n",
        "                            num_img, dig_img)\n",
        "            size = img.shape[0]\n",
        "            new_size = int(size/1.4)\n",
        "            img = img[size-new_size: size+new_size,\n",
        "                      size-new_size: size+new_size]\n",
        "            y[t] = j+1\n",
        "            t = t+1\n",
        "\n",
        "            # Preprocesar las imágenes según el color_mode (blue, red, green, blue)\n",
        "            if color_mode == 'gray':\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            elif color_mode == 'red':\n",
        "                img = img[:, :, 0]\n",
        "            elif color_mode == 'green':\n",
        "                img = img[:, :, 1]\n",
        "            elif color_mode == 'blue':\n",
        "                img = img[:, :, 2]\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid color mode: {color_mode}\")\n",
        "\n",
        "            # Extraer características según el feature_type\n",
        "            if feature_type == 'lbp':\n",
        "                # Aplicar LBP a cada imagen\n",
        "                features[t:, ] = lbp(img, hdiv=LBP_HDIV, vdiv=LBP_VDIV)\n",
        "\n",
        "            elif feature_type == 'haralick':\n",
        "                # Aplicar características de textura Haralick a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Haralick\n",
        "                features[t:, ] = haralick(img, distance=HAR_DISTANCE,)\n",
        "\n",
        "            elif feature_type == 'gabor':\n",
        "                # Aplicar filtro de Gabor a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Gabor\n",
        "                features[t:, ] = gabor(\n",
        "                    img, rotations=GAB_ROTATIONS, dilations=GAB_DILATATIONS)\n",
        "\n",
        "            elif feature_type == 'hog':\n",
        "                # Aplicar HOG a cada imagen\n",
        "                features[t:, ] = hog(img, orientations=HOG_ORIENTATIONS, pixels_per_cell=(\n",
        "                    img.shape[0], img.shape[1]), cells_per_block=(1, 1))\n",
        "\n",
        "            elif feature_type == 'zernike':\n",
        "                # Aplicar momentos de Zernike a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Zernike\n",
        "                features[t:, ] = zernike_moments(img, radius=ZER_RADIUS, degree=ZER_DEGREE)\n",
        "\n",
        "            elif feature_type == 'glcm':\n",
        "                img_uint = img.astype(np.uint8)\n",
        "                # Aplicar GLCM (Matriz de co-ocurrencia de niveles de gris) a cada imagen\n",
        "                glcm = graycomatrix(img_uint, [GLCM_DISTANCES], GLCM_ANGLES, levels=GLCM_LEVELS)\n",
        "                contrast = graycoprops(glcm, 'contrast')\n",
        "                # Compute desired GLCM properties (e.g., contrast, energy, correlation, etc.)\n",
        "                features[t:, ] = np.concatenate(contrast)\n",
        "\n",
        "            elif feature_type == 'daisy':\n",
        "                # Aplicar Daisy a cada imagen\n",
        "                features[t:, ] = daisy(img, step=DAISY_STEP, radius=DAISY_RADIUS, rings=DAISY_RINGS,\n",
        "                                    histograms=DAISY_HISTOGRAMS, orientations=DAISY_ORIENTATIONS).flatten()\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid feature_type: {feature_type}\")\n",
        "\n",
        "        features = np.array(features)\n",
        "\n",
        "    # Devolver las características extraídas y las etiquetas\n",
        "    return features, y\n",
        "\n",
        "\n",
        "def load_features(color, set, function):\n",
        "    # !wget https://www.dropbox.com/caracteristicas.npz?dl=0\n",
        "    # !mv caracteristicas.npz?dl=0 caracteristicas.npz\n",
        "\n",
        "    loaded_caracteristicas = np.load('caracteristicas.npz')\n",
        "    y = loaded_caracteristicas['y']\n",
        "    pass\n",
        "\n",
        "\n",
        "def select_features(xtrain, xtest, ytrain, algorithm, color, step=1):\n",
        "    # SELECCIÓN:\n",
        "    if algorithm == 'SFS':\n",
        "        # SFS: Sequential Feature Selection\n",
        "        selector = sfs(xtrain, ytrain, n_features=N_SFS, show=True)\n",
        "        np.save(f\"selection01_steps/sfs{step}_idxs_{color}.npy\", selector)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'EX':\n",
        "        # Exhaustive Search\n",
        "        selector = exsearch(xtrain, ytrain, N_EX)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'RFECV':\n",
        "        # Recursive Feature Elimination\n",
        "        estimator = SVC(kernel='linear')\n",
        "        selector = RFECV(estimator, step=RFECV_STEP, cv=5)\n",
        "        selector  = selector.fit(xtrain, ytrain)\n",
        "        selector       = np.nonzero(selector.support_)[0]\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'RFE':\n",
        "        # RFE\n",
        "        estimator = SVC(kernel='linear')\n",
        "        selector = RFE(estimator)\n",
        "        selector  = selector.fit(xtrain, ytrain)\n",
        "        selector  = np.nonzero(selector.support_)[0]\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'SBS':\n",
        "        # SBS\n",
        "        estimator = KNeighborsClassifier(n_neighbors=5)\n",
        "        selector = mlxsfs(estimator, k_features=N_SBS, forward=False, floating=False, verbose=SBS_VERBOSE, scoring='accuracy', cv=SBS_CV)\n",
        "        selector = selector.fit(xtrain, ytrain)\n",
        "        selector = list(selector.k_feature_idx_)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    # TRANSFORMACIÓN:\n",
        "    elif algorithm == 'PCA':\n",
        "        # PCA: Principal Component Analysis\n",
        "        Xtrain_sel, _, A, Xm, _  = pca(xtrain, n_components=N_PCA)\n",
        "        Xtest_sel = np.matmul(xtest - Xm, A)\n",
        "        np.save(f\"selection01_steps/pca_Xm{step}_{color}.npy\", Xm)\n",
        "        np.save(f\"selection01_steps/pca_A{step}_{color}.npy\", A)\n",
        "        print('PCA done')\n",
        "\n",
        "    elif algorithm == 'ICA':\n",
        "        # ICA: Independent Component Analysis\n",
        "        selector = FastICA(n_components=N_ICA, random_state=ICA_RANDOM_STATE)\n",
        "        selector.fit(xtrain, ytrain)\n",
        "        Xtrain_sel = selector.transform(xtrain)\n",
        "        Xtest_sel = selector.transform(xtest)\n",
        "    \n",
        "    elif algorithm == 'PLSR':\n",
        "        selector = PLSRegression(n_components=N_PLSR)\n",
        "        selector.fit(xtrain, ytrain)    \n",
        "        Xtrain_sel = selector.transform(xtrain)\n",
        "        Xtest_sel  = selector.transform(xtest)\n",
        "\n",
        "    # SELECCIÓN + TRANSFORMACIÓN:\n",
        "    elif algorithm == 'SEL_01':\n",
        "        Xtrain_sel, Xtest_sel = selection_01(xtrain, xtest, ytrain, color)\n",
        "\n",
        "    elif algorithm == 'SEL_02':\n",
        "        Xtrain_sel, Xtest_sel = selection_02(xtrain, xtest, ytrain)\n",
        "\n",
        "    elif algorithm == 'SEL_03':\n",
        "        Xtrain_sel, Xtest_sel = selection_03(xtrain, xtest, ytrain)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid algorithm: {algorithm}\")\n",
        "\n",
        "    return Xtrain_sel, Xtest_sel\n",
        "\n",
        "\n",
        "def load_selected_features(algorithm):\n",
        "    pass\n",
        "\n",
        "\n",
        "def load_classifier(classifier):\n",
        "    if classifier == 'knn':\n",
        "        return KNeighborsClassifier()\n",
        "    elif classifier == 'lda':\n",
        "        return LinearDiscriminantAnalysis()\n",
        "    elif classifier == 'qda':\n",
        "        return QuadraticDiscriminantAnalysis()\n",
        "    elif classifier == 'árboles de decisión':\n",
        "        return DecisionTreeClassifier()\n",
        "    elif classifier == 'random forest':\n",
        "        return RandomForestClassifier()\n",
        "    elif classifier == 'svm lineal':\n",
        "        return SVC(kernel='linear')\n",
        "    elif classifier == 'svm rbf':\n",
        "        return SVC(kernel='rbf')\n",
        "    elif classifier == 'redes neuronales':\n",
        "        return MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid classifier: {classifier}\")\n",
        "\n",
        "\n",
        "def load_trained_classifier():\n",
        "    pass\n",
        "\n",
        "\n",
        "def selection_01(Xtrain, Xtest, ytrain, color): \n",
        "    ''' clean-->Norm-->SFS--+-------+-->Concatenate-->SFS-->OUT\n",
        "                            |       |\n",
        "                            +--PCA--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    print(Xtrain.shape, color)\n",
        "    np.save(f\"selection01_steps/clean_{color}.npy\", sclean)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    np.save(f\"selection01_steps/norm_{color}.npy\", [a, b])\n",
        "    ### SFS 1 ###\n",
        "    print(Xtrain_norm.shape)\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS', color)\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PCA', color, step=2)\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_sfs1, Xtrain_pca), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_sfs1, Xtest_pca), axis=1)\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_aux, Xtest_aux, ytrain, 'SFS', color, step=2)\n",
        "    #######\n",
        "    return Xtrain_sfs2, Xtest_sfs2\n",
        "\n",
        "\n",
        "def selection_02(Xtrain, Xtest, ytrain):\n",
        "    '''\n",
        "                        +-->PCA---+\n",
        "                        |         |\n",
        "    clean-->Norm-->SFS--+-->ICA---+-->Concatenate-->SFS-->OUT\n",
        "                        |         |\n",
        "                        +-->PLSR--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    ### SFS 1 ###\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS')\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PCA')\n",
        "    ### PLSR ###\n",
        "    Xtrain_plsr, Xtest_plsr = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PLSR')\n",
        "    ### ICA ###\n",
        "    Xtrain_ica, Xtest_ica = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'ICA')\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_pca, Xtrain_ica, Xtrain_plsr), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_pca, Xtest_ica, Xtest_plsr), axis=1)\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_aux, Xtest_aux, ytrain, 'SFS')\n",
        "    #######\n",
        "    return Xtrain_sfs2, Xtest_sfs2\n",
        "\n",
        "\n",
        "def selection_03(Xtrain, Xtest, ytrain):\n",
        "    '''\n",
        "        clean-->Norm-->SFS-+-->EX---+-->PCA-->SFS-->OUT\n",
        "                           |        |\n",
        "                           +-->RFE--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    ### SFS 1 ###\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS')\n",
        "    ### Búsqueda Exhaustiva ###\n",
        "    Xtrain_ex, Xtest_ex = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'EX')\n",
        "    ### RFE ###\n",
        "    Xtrain_rfe, Xtest_rfe = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'RFE')\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_ex, Xtrain_rfe), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_ex, Xtest_rfe), axis=1)\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_aux, Xtest_aux, ytrain, 'PCA')\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_pca, Xtest_pca, ytrain, 'SFS')\n",
        "    return Xtrain_sfs2, Xtest_sfs2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6grN-iWqDGy1"
      },
      "source": [
        "### Cargar imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5gBOG_ia46U",
        "outputId": "16b6a2b4-0094-4a60-dcfa-5485fe8c41b5"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/s4opefjionbdbab/G00.zip\n",
        "!unzip -qq G00.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDobx-xnGYkm"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/zur2wxzcce4qlgf/G01.zip\n",
        "!unzip -qq G01.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0RIDrv8TabcL"
      },
      "source": [
        "## Extracción y selección de caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JNdYh_yVabcL"
      },
      "outputs": [],
      "source": [
        "def extraction_main(extraction_models, color_modes, image_set):\n",
        "    # Create the \"features\" folder if it doesn't exist\n",
        "    if not os.path.exists(\"features\"):\n",
        "        os.makedirs(\"features\")\n",
        "    if not os.path.exists(\"y\"):\n",
        "        os.makedirs(\"y\")\n",
        "\n",
        "    # Iterate over extraction models and color modes\n",
        "    for model in tqdm(extraction_models):\n",
        "        for color_mode in color_modes:\n",
        "            # Extract features\n",
        "            (X, y) = extract_features(color_mode, image_set, model)\n",
        "\n",
        "            # Save features to files\n",
        "            filename = f\"features/X_{image_set}_{model}_{color_mode}.npy\"\n",
        "            y_filename = f\"y/y_{image_set}.npy\"\n",
        "\n",
        "            np.save(filename, X)\n",
        "            np.save(y_filename, y)\n",
        "\n",
        "selection_models = ['SEL_01']\n",
        "\n",
        "color_modes = [\"gray\", \"blue\", \"red\", \"green\"]\n",
        "\n",
        "def select_main(selection_models, color_modes):\n",
        "\n",
        "    caract_modes = ['haralick', 'hog', 'zernike', 'lbp', 'glcm']\n",
        "    \n",
        "    # Create the \"features\" folder if it doesn't exist\n",
        "    if not os.path.exists(\"selected_features\"):\n",
        "        os.makedirs(\"selected_features\")\n",
        "\n",
        "    ytrain = np.load(f'y/y_train.npy')\n",
        "    ytest = np.load(f'y/y_test.npy')\n",
        "\n",
        "    ##CONCATENAR POR COLOR\n",
        "    Xtrain_gray     = np.load(f'features/X_train_haralick_gray.npy')\n",
        "    Xtest_gray      = np.load(f'features/X_test_haralick_gray.npy')\n",
        "    Xtrain_blue     = np.load(f'features/X_train_haralick_blue.npy')\n",
        "    Xtest_blue      = np.load(f'features/X_test_haralick_blue.npy')\n",
        "    Xtrain_red      = np.load(f'features/X_train_haralick_red.npy')\n",
        "    Xtest_red       = np.load(f'features/X_test_haralick_red.npy')\n",
        "    Xtrain_green    = np.load(f'features/X_train_haralick_green.npy')\n",
        "    Xtest_green     = np.load(f'features/X_test_haralick_green.npy')\n",
        "    for caract in caract_modes[1:]:\n",
        "        if (caract == \"lbp\") | (caract == \"daisy\"):\n",
        "            Xtrain_gray_aux, Xtest_gray_aux = select_features(np.load(f'features/X_train_{caract}_gray.npy'), np.load(f'features/X_test_{caract}_gray.npy'), ytrain, algorithm='PCA', color=\"gray\", step=caract)\n",
        "            Xtrain_blue_aux, Xtest_blue_aux = select_features(np.load(f'features/X_train_{caract}_blue.npy'), np.load(f'features/X_test_{caract}_blue.npy'), ytrain, algorithm='PCA', color=\"blue\", step=caract)\n",
        "            Xtrain_red_aux, Xtest_red_aux = select_features(np.load(f'features/X_train_{caract}_red.npy'), np.load(f'features/X_test_{caract}_red.npy'), ytrain, algorithm='PCA', color=\"red\", step=caract)\n",
        "            Xtrain_green_aux, Xtest_green_aux = select_features(np.load(f'features/X_train_{caract}_green.npy'), np.load(f'features/X_test_{caract}_green.npy'), ytrain, algorithm='PCA', color=\"green\", step=caract)\n",
        "        else:\n",
        "            Xtrain_gray_aux = np.load(f'features/X_train_{caract}_gray.npy')\n",
        "            Xtest_gray_aux  = np.load(f'features/X_test_{caract}_gray.npy')\n",
        "            Xtrain_blue_aux = np.load(f'features/X_train_{caract}_blue.npy')\n",
        "            Xtest_blue_aux  = np.load(f'features/X_test_{caract}_blue.npy')\n",
        "            Xtrain_red_aux = np.load(f'features/X_train_{caract}_red.npy')\n",
        "            Xtest_red_aux  = np.load(f'features/X_test_{caract}_red.npy')\n",
        "            Xtrain_green_aux = np.load(f'features/X_train_{caract}_green.npy')\n",
        "            Xtest_green_aux  = np.load(f'features/X_test_{caract}_green.npy')\n",
        "\n",
        "\n",
        "        Xtrain_gray     = np.concatenate((Xtrain_gray,  Xtrain_gray_aux), axis=1)\n",
        "        Xtest_gray      = np.concatenate((Xtest_gray,   Xtest_gray_aux), axis=1)\n",
        "        Xtrain_blue     = np.concatenate((Xtrain_blue,  Xtrain_blue_aux), axis=1)\n",
        "        Xtest_blue      = np.concatenate((Xtest_blue,   Xtest_blue_aux), axis=1)\n",
        "        Xtrain_red      = np.concatenate((Xtrain_red,   Xtrain_red_aux), axis=1)\n",
        "        Xtest_red       = np.concatenate((Xtest_red,    Xtest_red_aux), axis=1)\n",
        "        Xtrain_green    = np.concatenate((Xtrain_green, Xtrain_green_aux), axis=1)\n",
        "        Xtest_green     = np.concatenate((Xtest_green,  Xtest_green_aux), axis=1)\n",
        "\n",
        "    ##SELECCIONAR CARACTERISTICAS\n",
        "    for model in selection_models:\n",
        "\n",
        "        print('START SELECTION \\n')\n",
        "        Xtrain_sel_gray, Xtest_sel_gray = select_features(Xtrain_gray, Xtest_gray, ytrain, model, \"gray\")\n",
        "        print(f'Selection_gray_{model}')\n",
        "        np.save(f'selected_features/X_train_{model}_gray.npy', Xtrain_sel_gray)\n",
        "        np.save(f'selected_features/X_test_{model}_gray.npy', Xtest_sel_gray)\n",
        "\n",
        "        Xtrain_sel_blue, Xtest_sel_blue = select_features(Xtrain_blue, Xtest_blue, ytrain, model, \"blue\")\n",
        "        print(f'Selection_blue_{model}')\n",
        "        np.save(f'selected_features/X_train_{model}_blue.npy', Xtrain_sel_blue)\n",
        "        np.save(f'selected_features/X_test_{model}_blue.npy', Xtest_sel_blue)\n",
        "\n",
        "        Xtrain_sel_red, Xtest_sel_red = select_features(Xtrain_red, Xtest_red, ytrain, model, \"red\")\n",
        "        print(f'Selection_red_{model}')\n",
        "        np.save(f'selected_features/X_train_{model}_red.npy', Xtrain_sel_red)\n",
        "        np.save(f'selected_features/X_test_{model}_red.npy', Xtest_sel_red)\n",
        "\n",
        "        Xtrain_sel_green, Xtest_sel_green = select_features(Xtrain_green, Xtest_green, ytrain, model, \"green\")\n",
        "        print(f'Selection_green_{model}')\n",
        "        np.save(f'selected_features/X_train_{model}_green.npy', Xtrain_sel_green)\n",
        "        np.save(f'selected_features/X_test_{model}_green.npy', Xtest_sel_green)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xWOs66SSCFq_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        }
      ],
      "source": [
        "Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_01_gray.npy')\n",
        "Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_01_gray.npy')\n",
        "Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_01_blue.npy')\n",
        "Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_01_blue.npy')\n",
        "Xtrain_red_aux = np.load(f'selected_features/X_train_SEL_01_red.npy')\n",
        "Xtest_red_aux  = np.load(f'selected_features/X_test_SEL_01_red.npy')\n",
        "Xtrain_green_aux = np.load(f'selected_features/X_train_SEL_01_green.npy')\n",
        "Xtest_green_aux  = np.load(f'selected_features/X_test_SEL_01_green.npy')\n",
        "\n",
        "Xtrain = np.concatenate((Xtrain_gray_aux, Xtrain_blue_aux, Xtrain_red_aux, Xtrain_green_aux), axis=1)\n",
        "Xtest = np.concatenate((Xtest_gray_aux, Xtest_blue_aux, Xtest_red_aux, Xtest_green_aux), axis=1)\n",
        "ytrain = np.load(f'y/y_train.npy')\n",
        "\n",
        "Xtrain_sel, Xtest_sel = select_features(Xtrain, Xtest, ytrain, algorithm='PCA', step=\"all\", color=\"all\")\n",
        "\n",
        "np.save(f'selected_features/X_train_SEL_01_all.npy', Xtrain_sel)\n",
        "np.save(f'selected_features/X_test_SEL_01_all.npy', Xtest_sel)\n",
        "\n",
        "# Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_02_gray.npy')\n",
        "# Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_02_gray.npy')\n",
        "# Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_02_blue.npy')\n",
        "# Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_02_blue.npy')\n",
        "# Xtrain_red_aux = np.load(f'selected_features/X_train_SEL_02_red.npy')\n",
        "# Xtest_red_aux  = np.load(f'selected_features/X_test_SEL_02_red.npy')\n",
        "# Xtrain_green_aux = np.load(f'selected_features/X_train_SEL_02_green.npy')\n",
        "# Xtest_green_aux  = np.load(f'selected_features/X_test_SEL_02_green.npy')\n",
        "\n",
        "# Xtrain = np.concatenate((Xtrain_gray_aux, Xtrain_blue_aux, Xtrain_red_aux, Xtrain_green_aux), axis=1)\n",
        "# Xtest = np.concatenate((Xtest_gray_aux, Xtest_blue_aux, Xtest_red_aux, Xtest_green_aux), axis=1)\n",
        "\n",
        "# Xtrain_sel, Xtest_sel = select_features(Xtrain, Xtest, ytrain, algorithm='PCA')\n",
        "\n",
        "# np.save(f'selected_features/X_train_SEL_02_all.npy', Xtrain_sel)\n",
        "# np.save(f'selected_features/X_test_SEL_02_all.npy', Xtest_sel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1080, 100)\n",
            "(360, 100)\n",
            "(1080, 100)\n",
            "(360, 100)\n"
          ]
        }
      ],
      "source": [
        "Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_01_gray.npy')\n",
        "Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_01_gray.npy')\n",
        "\n",
        "Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_02_blue.npy')\n",
        "Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_02_blue.npy')\n",
        "\n",
        "print(Xtrain_gray_aux.shape)\n",
        "print(Xtest_gray_aux.shape)\n",
        "print(Xtrain_blue_aux.shape)\n",
        "print(Xtest_blue_aux.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_y248SgabcP"
      },
      "source": [
        "## Clasificación"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### De acá en adelante se pueden ejecutar los modelos 1 y 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ARCHIVOS CON CARACTERISTICAS SELECCIONADAS\n",
        "\n",
        "!wget https://www.dropbox.com/s/tivfqnxt8cbz3yq/selected.zip\n",
        "!unzip -qq selected.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1vq1gxv4abcP"
      },
      "source": [
        "descargar caracteristicas seleccionadas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "58_8ANIKabcQ"
      },
      "source": [
        "### Ensamble de clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vO29jXRHabcR"
      },
      "outputs": [],
      "source": [
        "def majority_voting_ensemble(models, X_test):\n",
        "    predictions = np.array([model.predict(X_test) for model in models])\n",
        "    majority_vote = mode(predictions, axis=0)\n",
        "    return majority_vote.mode.flatten()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TjLhuqazabcR"
      },
      "source": [
        "## MODELO 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "at7D1MayabcR"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mbNN5vsEabcR"
      },
      "outputs": [],
      "source": [
        "def modelo_1(X_train, y_train):\n",
        "\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "          \n",
        "    # Dividir el conjunto de entrenamiento en entrenamiento y prueba (Hold Out)\n",
        "    X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train, y_train, test_size=4, random_state=42)\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Iterar sobre diferentes modelos y encontrar el que maximice la precisión\n",
        "    for model in models:\n",
        "        # Entrenar el modelo con el conjunto de entrenamiento\n",
        "        model.fit(X_train_1, y_train_1)\n",
        "\n",
        "        # Predecir las etiquetas para el conjunto de prueba\n",
        "        y_pred = model.predict(X_test_1)\n",
        "\n",
        "        # Calcular la precisión del modelo\n",
        "        accuracy = accuracy_score(y_test_1, y_pred)\n",
        "\n",
        "        # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "        model.fit(X_train, y_train)\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "    \n",
        "    # Entregar el mejor modelo encontrado\n",
        "    entregable_modelo_1 = best_model\n",
        "\n",
        "    return models, entregable_modelo_1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4S7unylpabcS"
      },
      "source": [
        "## MODELO 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XnwyRdKQabcS"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RC4ysEONabcS"
      },
      "outputs": [],
      "source": [
        "def model_2(X_train, y_train):\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    # Iterar sobre diferentes modelos y encontrar el que maximice la precisión en cross-val\n",
        "    for model in models:\n",
        "        # Realizar cross-val con 4 folds en las imágenes de grupo 0\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=4)\n",
        "\n",
        "        # Calcular la precisión promedio en cross-val\n",
        "        accuracy = scores.mean()\n",
        "\n",
        "        # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "        model.fit(X_train, y_train)\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    # Entregar el mejor modelo encontrado\n",
        "    entregable_modelo_2 = best_model\n",
        "\n",
        "    return models, entregable_modelo_2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODELO 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_3(X, y):\n",
        "\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    n_folds = 5\n",
        "    skf = StratifiedKFold(n_splits=n_folds)\n",
        "\n",
        "    for model in models:\n",
        "      accuracies = np.array([])\n",
        "      for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "            X_train_3, X_test_3 = X[train_index], X[test_index]\n",
        "            y_train_3, y_test_3 = y[train_index], y[test_index]\n",
        "\n",
        "            model.fit(X_train_3, y_train_3)\n",
        "\n",
        "            y_pred = model.predict(X_test_3)\n",
        "\n",
        "            accuracy = accuracy_score(y_test_3, y_pred)\n",
        "            \n",
        "            accuracies = np.append(accuracies, accuracy)\n",
        "      mean_accuracy = np.mean(accuracies)\n",
        "\n",
        "      if mean_accuracy > best_accuracy:\n",
        "            best_accuracy = mean_accuracy\n",
        "            best_model = model\n",
        "\n",
        "      best_model.fit(X, y)\n",
        "\n",
        "    return models, best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = np.load('y/y_train.npy')\n",
        "y_test = np.load('y/y_test.npy')\n",
        "\n",
        "accs_m1 = {}\n",
        "accs_m2 = {}\n",
        "\n",
        "all_files = [\"red\", \"green\", \"blue\", \"gray\"]\n",
        "for n in [1, 2]:\n",
        "    accs_m1[n] = {}\n",
        "    accs_m2[n] = {}\n",
        "    for i in all_files:\n",
        "        X_train = np.load(f'selected_features/X_train_SEL_0{n}_{i}.npy')\n",
        "        X_test = np.load(f'selected_features/X_test_SEL_0{n}_{i}.npy')\n",
        "\n",
        "        ##MODELO 1\n",
        "        models, best_model_1 = modelo_1(X_train, y_train)\n",
        "        y_pred_1 = best_model_1.predict(X_test)\n",
        "        accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
        "        \n",
        "        print(f\"Accuracy model 1: {accuracy_1}\")\n",
        "        accs_m1[n][i] = accuracy_1\n",
        "\n",
        "        y_pred_mv = majority_voting_ensemble(models, X_test)\n",
        "        accuracy_mv = accuracy_score(y_test, y_pred_mv)\n",
        "\n",
        "        print(f\"Accuracy majority voting: {accuracy_mv}\")\n",
        "        accs_m1[n][f'{i}_mv'] = accuracy_mv\n",
        "\n",
        "        ## MODELO 2\n",
        "        models, best_model_2 = model_2(X_train, y_train)\n",
        "        y_pred_2 = best_model_2.predict(X_test)\n",
        "        accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
        "\n",
        "        print(f\"Accuracy model 2: {accuracy_2}\")\n",
        "        accs_m2[n][i] = accuracy_2\n",
        "\n",
        "        y_pred_mv = majority_voting_ensemble(models, X_test)\n",
        "        accuracy_mv = accuracy_score(y_test, y_pred_mv)\n",
        "\n",
        "        print(f\"Accuracy majority voting: {accuracy_mv}\")\n",
        "        accs_m2[n][f'{i}_mv'] = accuracy_mv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: {'red': 0.6611111111111111, 'red_mv': 0.6444444444444445, 'green': 0.6361111111111111, 'green_mv': 0.6333333333333333, 'blue': 0.6222222222222222, 'blue_mv': 0.6083333333333333, 'gray': 0.6416666666666667, 'gray_mv': 0.6222222222222222}, 2: {'red': 0.6611111111111111, 'red_mv': 0.5416666666666666, 'green': 0.6361111111111111, 'green_mv': 0.5111111111111111, 'blue': 0.6222222222222222, 'blue_mv': 0.5138888888888888, 'gray': 0.6444444444444445, 'gray_mv': 0.5361111111111111}}\n",
            "{1: {'red': 0.6611111111111111, 'red_mv': 0.6472222222222223, 'green': 0.6361111111111111, 'green_mv': 0.6388888888888888, 'blue': 0.6222222222222222, 'blue_mv': 0.6083333333333333, 'gray': 0.6416666666666667, 'gray_mv': 0.6305555555555555}, 2: {'red': 0.6611111111111111, 'red_mv': 0.5555555555555556, 'green': 0.6361111111111111, 'green_mv': 0.5166666666666667, 'blue': 0.6222222222222222, 'blue_mv': 0.5083333333333333, 'gray': 0.6444444444444445, 'gray_mv': 0.5333333333333333}}\n"
          ]
        }
      ],
      "source": [
        "print(accs_m1)\n",
        "print(accs_m2)\n",
        "\n",
        "np.save('accs_m1.npy', accs_m1)\n",
        "np.save('accs_m2.npy', accs_m2)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Código para ejecutar tests"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insertar link en la celda de abajo y ejecutar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget <url>\n",
        "!unzip -qq G02.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si no está cargado el G01.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/zur2wxzcce4qlgf/G01.zip\n",
        "!unzip -qq G01.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cargar selected_features, selection_steps e y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/f22yzeacl2y2wbn/selected_features.zip\n",
        "!wget https://www.dropbox.com/s/1fngntbr9bdpy1s/selection01_steps.zip\n",
        "!wget https://www.dropbox.com/s/vk56ogri85txlpt/y.zip\n",
        "\n",
        "!unzip -qq selected_features.zip\n",
        "!unzip -qq selection01_steps.zip\n",
        "!unzip -qq y.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutar celda de abajo para probar, cambiar TEST por \"test\" o \"test2\", siendo G01 Y G02 respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a3fc785958440b1a8f6f86c050351fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "694405eb76a44728ade5ec670be2e3a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bda9448963224e5a80405cf1a44fbaed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2018fdcac5ef42abb240d01e62eaed69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39c37712e7294b57a80f4137e437cd91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3ec8a8ba28c40c28b9965a795b4e5ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6199a601169d4de1b31a3a99c5ac7c6d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f056b4958bb4501b19986e7c06e0de7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60ea5333d88343b997f479c0f467ed7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "108dde5118784977b81bf60592def8f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc59be7f01aa456b89339f966ab5afc7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d9b6d55c32a4b82986069d671171233",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "262979dfdd574118b7b4d756705589ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9139c406d304700a56d198c8e17b1db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ffa3bc90fe04647b3f2dce44b2a360a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fe99e3993c740a494bc00a979d718e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ab9b2c705b74188954aa375a3a29acd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51b73d0e9c704a748a90be138db93a28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "136258b3d2f34990bc752a531d73374a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2cc55927c8a46aa92d38ef79db6ca13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a8ed0fb48724be4b01bc73539f107e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy model 1: 0.6055555555555555\n",
            "Accuracy model 2: 0.6055555555555555\n",
            "Accuracy model 3: 0.6055555555555555\n"
          ]
        }
      ],
      "source": [
        "TEST = \"test\"\n",
        "EXTRACTION_MODS = ['haralick', 'hog', 'zernike', 'lbp', 'glcm']\n",
        "COLOR_MODES = [\"gray\", \"blue\", \"red\", \"green\"]\n",
        "SELECTION_MODELS = ['SEL_01']\n",
        "\n",
        "\n",
        "def select01_test_features(test_set):\n",
        "    Xtest_gray = None\n",
        "    Xtest_blue = None\n",
        "    Xtest_red = None\n",
        "    Xtest_green = None\n",
        "    for caract in EXTRACTION_MODS:\n",
        "        Xtest_gray_aux = np.load(f'features/X_{test_set}_{caract}_gray.npy')\n",
        "        Xtest_blue_aux = np.load(f'features/X_{test_set}_{caract}_blue.npy')\n",
        "        Xtest_red_aux = np.load(f'features/X_{test_set}_{caract}_red.npy')\n",
        "        Xtest_green_aux = np.load(f'features/X_{test_set}_{caract}_green.npy')\n",
        "        if (caract == \"lbp\") | (caract == \"daisy\"):\n",
        "            Xm_gray, A_gray = np.load(f'selection01_steps/pca_Xm{caract}_gray.npy'), np.load(f'selection01_steps/pca_A{caract}_gray.npy')\n",
        "            Xm_blue, A_blue = np.load(f'selection01_steps/pca_Xm{caract}_blue.npy'), np.load(f'selection01_steps/pca_A{caract}_blue.npy')\n",
        "            Xm_red, A_red = np.load(f'selection01_steps/pca_Xm{caract}_red.npy'), np.load(f'selection01_steps/pca_A{caract}_red.npy')\n",
        "            Xm_green, A_green = np.load(f'selection01_steps/pca_Xm{caract}_green.npy'), np.load(f'selection01_steps/pca_A{caract}_green.npy')\n",
        "            \n",
        "            Xtest_gray_aux = np.matmul(Xtest_gray_aux - Xm_gray, A_gray)\n",
        "            Xtest_blue_aux = np.matmul(Xtest_blue_aux - Xm_blue, A_blue)\n",
        "            Xtest_red_aux = np.matmul(Xtest_red_aux - Xm_red, A_red)\n",
        "            Xtest_green_aux = np.matmul(Xtest_green_aux - Xm_green, A_green)\n",
        "        if Xtest_gray is None:\n",
        "            Xtest_gray = Xtest_gray_aux\n",
        "            Xtest_blue = Xtest_blue_aux\n",
        "            Xtest_red = Xtest_red_aux\n",
        "            Xtest_green = Xtest_green_aux\n",
        "        else:\n",
        "            Xtest_gray = np.concatenate((Xtest_gray,   Xtest_gray_aux), axis=1)\n",
        "            Xtest_blue = np.concatenate((Xtest_blue,   Xtest_blue_aux), axis=1)\n",
        "            Xtest_red = np.concatenate((Xtest_red,    Xtest_red_aux), axis=1)\n",
        "            Xtest_green = np.concatenate((Xtest_green,  Xtest_green_aux), axis=1)\n",
        "\n",
        "    # Pasos de SEL_01\n",
        "    \n",
        "    # Se aplica clean segun datos guardados de el entrenamiento\n",
        "    clean_gray = np.load(f'selection01_steps/clean_gray.npy')\n",
        "    clean_blue = np.load(f'selection01_steps/clean_blue.npy')\n",
        "    clean_red = np.load(f'selection01_steps/clean_red.npy')\n",
        "    clean_green = np.load(f'selection01_steps/clean_green.npy')\n",
        "    \n",
        "    Xtest_gray = Xtest_gray[:,clean_gray]\n",
        "    Xtest_blue = Xtest_blue[:,clean_blue]\n",
        "    Xtest_red = Xtest_red[:,clean_red]\n",
        "    Xtest_green = Xtest_green[:,clean_green]\n",
        "    \n",
        "    # Se aplica normalizacion segun datos guardados de el entrenamiento\n",
        "    norm_gray = np.load(f'selection01_steps/norm_gray.npy')\n",
        "    norm_blue = np.load(f'selection01_steps/norm_blue.npy')\n",
        "    norm_red = np.load(f'selection01_steps/norm_red.npy')\n",
        "    norm_green = np.load(f'selection01_steps/norm_green.npy')\n",
        "    \n",
        "    X_test_gray = Xtest_gray * norm_gray[0] + norm_gray[1]\n",
        "    X_test_blue = Xtest_blue * norm_blue[0] + norm_blue[1]\n",
        "    X_test_red = Xtest_red * norm_red[0] + norm_red[1]\n",
        "    X_test_green = Xtest_green * norm_green[0] + norm_green[1]\n",
        "    \n",
        "    # Se aplica el primer SFS segun datos guardados de el entrenamiento\n",
        "    sfs1_gray = np.load(f'selection01_steps/sfs1_idxs_gray.npy')\n",
        "    sfs1_blue = np.load(f'selection01_steps/sfs1_idxs_blue.npy')\n",
        "    sfs1_red = np.load(f'selection01_steps/sfs1_idxs_red.npy')\n",
        "    sfs1_green = np.load(f'selection01_steps/sfs1_idxs_green.npy')\n",
        "    \n",
        "    X_test_gray_sfs = X_test_gray[:,sfs1_gray]\n",
        "    X_test_blue_sfs = X_test_blue[:,sfs1_blue]\n",
        "    X_test_red_sfs = X_test_red[:,sfs1_red]\n",
        "    X_test_green_sfs = X_test_green[:,sfs1_green]\n",
        "    \n",
        "    # Se aplica PCA segun datos guardados de el entrenamiento\n",
        "    Xm_gray, A_gray = np.load(f'selection01_steps/pca_Xm2_gray.npy'), np.load(f'selection01_steps/pca_A2_gray.npy')\n",
        "    Xm_blue, A_blue = np.load(f'selection01_steps/pca_Xm2_blue.npy'), np.load(f'selection01_steps/pca_A2_blue.npy')\n",
        "    Xm_red, A_red = np.load(f'selection01_steps/pca_Xm2_red.npy'), np.load(f'selection01_steps/pca_A2_red.npy')\n",
        "    Xm_green, A_green = np.load(f'selection01_steps/pca_Xm2_green.npy'), np.load(f'selection01_steps/pca_A2_green.npy')\n",
        "    \n",
        "    X_test_gray_pca = np.matmul(X_test_gray_sfs - Xm_gray, A_gray)\n",
        "    X_test_blue_pca = np.matmul(X_test_blue_sfs - Xm_blue, A_blue)\n",
        "    X_test_red_pca = np.matmul(X_test_red_sfs - Xm_red, A_red)\n",
        "    X_test_green_pca = np.matmul(X_test_green_sfs - Xm_green, A_green)\n",
        "    \n",
        "    # Se concatenan SFS y PCA\n",
        "    X_test_gray = np.concatenate((X_test_gray_sfs, X_test_gray_pca), axis=1)\n",
        "    X_test_blue = np.concatenate((X_test_blue_sfs, X_test_blue_pca), axis=1)\n",
        "    X_test_red = np.concatenate((X_test_red_sfs, X_test_red_pca), axis=1)\n",
        "    X_test_green = np.concatenate((X_test_green_sfs, X_test_green_pca), axis=1)\n",
        "    \n",
        "    # Se aplica último SFS segun datos guardados de el entrenamiento\n",
        "    sfs2_gray = np.load(f'selection01_steps/sfs2_idxs_gray.npy')\n",
        "    sfs2_blue = np.load(f'selection01_steps/sfs2_idxs_blue.npy')\n",
        "    sfs2_red = np.load(f'selection01_steps/sfs2_idxs_red.npy')\n",
        "    sfs2_green = np.load(f'selection01_steps/sfs2_idxs_green.npy')\n",
        "    \n",
        "    X_test_gray = X_test_gray[:,sfs2_gray]\n",
        "    X_test_blue = X_test_blue[:,sfs2_blue]\n",
        "    X_test_red = X_test_red[:,sfs2_red]\n",
        "    X_test_green = X_test_green[:,sfs2_green]\n",
        "    \n",
        "    X_test = np.concatenate((X_test_gray, X_test_blue, X_test_red, X_test_green), axis=1)\n",
        "    \n",
        "    # Se aplica ultimo PCA segun datos guardados de el entrenamiento\n",
        "    Xm_all, A_all = np.load(f'selection01_steps/pca_Xmall_all.npy'), np.load(f'selection01_steps/pca_Aall_all.npy')\n",
        "    \n",
        "    X_test = np.matmul(X_test - Xm_all, A_all)\n",
        "    \n",
        "    return X_test\n",
        "    \n",
        "\n",
        "def test_set(test_set):\n",
        "    # select_main(SELECTION_MODELS, COLOR_MODES)\n",
        "    # return\n",
        "    # Cargar entrenamiento\n",
        "    X_train = np.load('selected_features/X_train_SEL_01_all.npy')\n",
        "    y_train = np.load('y/y_train.npy')\n",
        "\n",
        "    # Crear set de test\n",
        "    extraction_main(EXTRACTION_MODS, COLOR_MODES, test_set)\n",
        "    \n",
        "    X_test = select01_test_features(test_set)\n",
        "    y_test = np.load(f'y/y_{test_set}.npy')\n",
        "\n",
        "    ##MODELO 1\n",
        "    models, best_model_1 = modelo_1(X_train, y_train)\n",
        "    y_pred_1 = best_model_1.predict(X_test)\n",
        "    accuracy_m1 = accuracy_score(y_test, y_pred_1)\n",
        "    \n",
        "    print(f\"Accuracy model 1: {accuracy_m1}\")\n",
        "\n",
        "    ## MODELO 2\n",
        "    models, best_model_2 = model_2(X_train, y_train)\n",
        "    y_pred_2 = best_model_2.predict(X_test)\n",
        "    accuracy_m2 = accuracy_score(y_test, y_pred_2)\n",
        "\n",
        "    print(f\"Accuracy model 2: {accuracy_m2}\")\n",
        "    \n",
        "    ## MODELO 3\n",
        "    models, best_model_3 = model_3(X_train, y_train)\n",
        "    y_pred_3 = best_model_3.predict(X_test)\n",
        "    accuracy_m3 = accuracy_score(y_test, y_pred_3)\n",
        "\n",
        "    print(f\"Accuracy model 3: {accuracy_m3}\")\n",
        "    \n",
        "\n",
        "\n",
        "test_set(TEST)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
