{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VN9CHgR9abcE"
      },
      "source": [
        "# PROYECTO 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud6KEYvHabcH"
      },
      "source": [
        "Descripción proyecto"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "43IO1yccabcI"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install numpy --upgrade\n",
        "%pip install mahotas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5ghE_GnuabcJ",
        "outputId": "cc65cb88-c78d-4de1-f395-a7e92b743d9e"
      },
      "outputs": [],
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Procesamiento de imagenes\n",
        "import cv2\n",
        "\n",
        "# Visualizacion\n",
        "from   tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extraccion/seleccion de caracteristicas, clasificacion, evaluacion\n",
        "from   balu3.fx.geo    import fourierdes, hugeo, flusser, gupta,basicgeo # caracteristicas geometricas?\n",
        "from   balu3.fx.chr    import lbp, haralick, gabor, hog\n",
        "from   balu3.ft.norm   import minmax\n",
        "from   balu3.fs.sel    import jfisher,sfs,clean, exsearch\n",
        "from   balu3.io.misc   import imageload\n",
        "from   balu3.cl.basics import ClassifierKNN\n",
        "from   balu3.ft.trans  import pca\n",
        "from scipy.stats import mode\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.measure import moments\n",
        "from skimage.feature import graycomatrix, daisy, graycoprops\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, RFE, RFECV, mutual_info_classif ## fisher_score, \n",
        "from sklearn.cross_decomposition import PLSRegression \n",
        "\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as mlxsfs\n",
        "from mahotas.features import zernike_moments\n",
        "# img = plt.imread(\"G00/ID004_003.png\")\n",
        "# img = img[:, :, 2]\n",
        "# img = img[400-int(400/1.4) : 400+int(400/1.4), 400-int(400/1.4) : 400+int(400/1.4)]\n",
        "# print(img.shape)\n",
        "# descs = hog(img, orientations=HOG_ORIENTATIONS, pixels_per_cell=(\n",
        "#                     img.shape[0], img.shape[1]), cells_per_block=(1, 1))\n",
        "# print(descs.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'lbp': 531, 'haralick': 24, 'gabor': 67, 'hog': 9, 'zernike': 25, 'glcm': 1, 'daisy': 768}\n"
          ]
        }
      ],
      "source": [
        "IMG_WIDTH = IMG_HEIGHT = (400 // 1.4) * 2\n",
        "\n",
        "# LBP\n",
        "LBP_HDIV = LBP_VDIV = 3\n",
        "LBP_BINS = 59\n",
        "\n",
        "# Haralick\n",
        "HAR_DISTANCE = 3\n",
        "HAR_SIZE = 24\n",
        "\n",
        "# Gabor\n",
        "GAB_ROTATIONS = 8\n",
        "GAB_DILATATIONS = 8\n",
        "\n",
        "# HOG\n",
        "HOG_ORIENTATIONS = 9\n",
        "\n",
        "# Zernike\n",
        "ZER_RADIUS = 30\n",
        "ZER_DEGREE = 8\n",
        "ZER_SIZE = 25\n",
        "\n",
        "# GLCM\n",
        "GLCM_DISTANCES = 1\n",
        "GLCM_ANGLES = 0 \n",
        "GLCM_LEVELS = 256\n",
        "\n",
        "GLCM_SIZE = 1\n",
        "\n",
        "# Daisy\n",
        "DAISY_RINGS = 1\n",
        "DAISY_STEP = 150\n",
        "DAISY_RADIUS = 50\n",
        "DAISY_ORIENTATIONS = 8\n",
        "DAISY_HISTOGRAMS = 5\n",
        "DAISY_P = math.ceil((IMG_WIDTH - DAISY_RADIUS * 2) / DAISY_STEP) \n",
        "DAISY_Q = math.ceil((IMG_HEIGHT - DAISY_RADIUS * 2) / DAISY_STEP)\n",
        "DAISY_R = (DAISY_RINGS * DAISY_HISTOGRAMS + 1) * DAISY_ORIENTATIONS\n",
        "\n",
        "# Fetaures\n",
        "features_per_function = {\n",
        "    \"lbp\": LBP_HDIV * LBP_VDIV * LBP_BINS,\n",
        "    \"haralick\": HAR_SIZE,\n",
        "    \"gabor\": GAB_ROTATIONS * GAB_DILATATIONS + 3,\n",
        "    \"hog\": HOG_ORIENTATIONS,\n",
        "    \"zernike\": ZER_SIZE,\n",
        "    \"glcm\": GLCM_SIZE,\n",
        "    \"daisy\": DAISY_P * DAISY_Q * DAISY_R\n",
        "}\n",
        "print(features_per_function)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros Selección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SFS\n",
        "N_SFS = 100\n",
        "\n",
        "# Exhaustive\n",
        "N_EX = 5\n",
        "\n",
        "# RFECV\n",
        "RFECV_STEP = 1\n",
        "RFECV_CV = 5\n",
        "\n",
        "# SBS\n",
        "N_SBS = 100\n",
        "SBS_VERBOSE = 2\n",
        "SBS_CV = 100\n",
        "\n",
        "# PCA\n",
        "N_PCA = 100\n",
        "\n",
        "# ICA\n",
        "N_ICA = 100\n",
        "ICA_RANDOM_STATE = 0\n",
        "\n",
        "# PLSR\n",
        "N_PLSR = 100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfP13LKRabcK"
      },
      "source": [
        "### Funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Si6OrksrabcK"
      },
      "outputs": [],
      "source": [
        "LBP_HDIV = LBP_VDIV = 3\n",
        "DAISY_RINGS = 1\n",
        "\n",
        "\n",
        "def extract_features(color_mode, dataset_type, feature_type):\n",
        "    # Cargar rutas de imágenes y etiquetas según el dataset_type\n",
        "    # ...\n",
        "    K = 90   # <= NUMERO DE CLASES\n",
        "\n",
        "    if dataset_type == 'train':\n",
        "        fpath = \"G00\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 12   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12)\n",
        "\n",
        "    elif dataset_type == 'test1':\n",
        "        fpath = \"G01\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 4   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12, 16)\n",
        "\n",
        "    elif dataset_type == 'test2':\n",
        "        fpath = \"G02\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 4   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(16, 20)\n",
        "\n",
        "    dig_clase = 3     # <= NÚMERO DE DÍGITOS POR CLASE\n",
        "    dig_img = 3     # <= NÚMERO DE DÍGITOS POR NÚMERO DE IMAGEN\n",
        "    prefix = \"ID\"     # <= PREFIJO DEL NOMBRE DEL ARCHIVO DE LA IMAGEN\n",
        "    imprefix = fpath + '/' + prefix\n",
        "\n",
        "    # ground truth (clasificacion ideal)\n",
        "    y = np.zeros((K*N), 'int')\n",
        "    features = np.zeros((K*N, features_per_function[feature_type]))\n",
        "\n",
        "    t = 0\n",
        "    for j in range(K):                  # para cada clase\n",
        "        for i in tqdm(n):                # para cada imagen de la clase\n",
        "            # Lectura de la imagen\n",
        "            clase = j+1\n",
        "            num_img = i+1\n",
        "            img = imageload(imprefix, clase, dig_clase,\n",
        "                            num_img, dig_img, echo='on')\n",
        "            size = img.shape[0]\n",
        "            new_size = int(size/1.4)\n",
        "            img = img[size-new_size: size+new_size,\n",
        "                      size-new_size: size+new_size]\n",
        "            y[t] = j+1\n",
        "            t = t+1\n",
        "\n",
        "            # Preprocesar las imágenes según el color_mode (blue, red, green, blue)\n",
        "            if color_mode == 'gray':\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            elif color_mode == 'red':\n",
        "                img = img[:, :, 0]\n",
        "            elif color_mode == 'green':\n",
        "                img = img[:, :, 1]\n",
        "            elif color_mode == 'blue':\n",
        "                img = img[:, :, 2]\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid color mode: {color_mode}\")\n",
        "\n",
        "            # Extraer características según el feature_type\n",
        "            if feature_type == 'lbp':\n",
        "                # Aplicar LBP a cada imagen\n",
        "                features[t:, ] = lbp(img, hdiv=LBP_HDIV, vdiv=LBP_VDIV)\n",
        "\n",
        "            elif feature_type == 'haralick':\n",
        "                # Aplicar características de textura Haralick a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Haralick\n",
        "                features[t:, ] = haralick(img, distance=HAR_DISTANCE,)\n",
        "\n",
        "            elif feature_type == 'gabor':\n",
        "                # Aplicar filtro de Gabor a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Gabor\n",
        "                features[t:, ] = gabor(\n",
        "                    img, rotations=GAB_ROTATIONS, dilations=GAB_DILATATIONS)\n",
        "\n",
        "            elif feature_type == 'hog':\n",
        "                # Aplicar HOG a cada imagen\n",
        "                features[t:, ] = hog(img, orientations=HOG_ORIENTATIONS, pixels_per_cell=(\n",
        "                    img.shape[0], img.shape[1]), cells_per_block=(1, 1))\n",
        "\n",
        "            elif feature_type == 'zernike':\n",
        "                # Aplicar momentos de Zernike a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Zernike\n",
        "                features[t:, ] = zernike_moments(img, radius=ZER_RADIUS, degree=ZER_DEGREE)\n",
        "\n",
        "            elif feature_type == 'glcm':\n",
        "                img_uint = img.astype(np.uint8)\n",
        "                # Aplicar GLCM (Matriz de co-ocurrencia de niveles de gris) a cada imagen\n",
        "                glcm = graycomatrix(img_uint, [GLCM_DISTANCES], [GLCM_ANGLES], levels=GLCM_LEVELS)\n",
        "                contrast = graycoprops(glcm, 'contrast')\n",
        "                # Compute desired GLCM properties (e.g., contrast, energy, correlation, etc.)\n",
        "                features[t:, ] = np.concatenate(contrast)\n",
        "\n",
        "            elif feature_type == 'daisy':\n",
        "                # Aplicar Daisy a cada imagen\n",
        "                features[t:, ] = daisy(img, step=DAISY_STEP, radius=DAISY_RADIUS, rings=DAISY_RINGS,\n",
        "                                    histograms=DAISY_HISTOGRAMS, orientations=DAISY_ORIENTATIONS).flatten()\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid feature_type: {feature_type}\")\n",
        "\n",
        "        features = np.array(features)\n",
        "\n",
        "    # Devolver las características extraídas y las etiquetas\n",
        "    return features, y\n",
        "\n",
        "\n",
        "def load_features(color, set, function):\n",
        "    # !wget https://www.dropbox.com/caracteristicas.npz?dl=0\n",
        "    # !mv caracteristicas.npz?dl=0 caracteristicas.npz\n",
        "\n",
        "    loaded_caracteristicas = np.load('caracteristicas.npz')\n",
        "    y = loaded_caracteristicas['y']\n",
        "    pass\n",
        "\n",
        "\n",
        "def select_features(xtrain, xtest, ytrain, algorithm):\n",
        "    # SELECCIÓN:\n",
        "    if algorithm == 'SFS':\n",
        "        # SFS: Sequential Feature Selection\n",
        "        selector = sfs(xtrain, ytrain, n_features=N_SFS, show=True)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'EX':\n",
        "        # Exhaustive Search\n",
        "        selector = exsearch(xtrain, ytrain, N_EX)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'RFECV':\n",
        "        # Recursive Feature Elimination\n",
        "        estimator = SVC(kernel='linear')\n",
        "        selector = RFECV(estimator, step=RFECV_STEP, cv=5)\n",
        "        selector  = selector.fit(xtrain, ytrain)\n",
        "        selector       = np.nonzero(selector.support_)[0]\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'RFE':\n",
        "        # RFE\n",
        "        estimator = SVC(kernel='linear')\n",
        "        selector = RFE(estimator)\n",
        "        selector  = selector.fit(xtrain, ytrain)\n",
        "        selector  = np.nonzero(selector.support_)[0]\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'SBS':\n",
        "        # SBS\n",
        "        estimator = KNeighborsClassifier(n_neighbors=5)\n",
        "        selector = mlxsfs(estimator, k_features=N_SBS, forward=False, floating=False, verbose=SBS_VERBOSE, scoring='accuracy', cv=SBS_CV)\n",
        "        selector = selector.fit(xtrain, ytrain)\n",
        "        selector = list(selector.k_feature_idx_)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    # TRANSFORMACIÓN:\n",
        "    elif algorithm == 'PCA':\n",
        "        # PCA: Principal Component Analysis\n",
        "        Xtrain_sel, _, A, Xm, _  = pca(xtrain, n_components=N_PCA)\n",
        "        Xtest_sel = np.matmul(xtest - Xm, A)\n",
        "        print('PCA done')\n",
        "\n",
        "    elif algorithm == 'ICA':\n",
        "        # ICA: Independent Component Analysis\n",
        "        selector = FastICA(n_components=N_ICA, random_state=ICA_RANDOM_STATE)\n",
        "        selector.fit(xtrain, ytrain)\n",
        "        Xtrain_sel = selector.transform(xtrain)\n",
        "        Xtest_sel = selector.transform(xtest)\n",
        "    \n",
        "    elif algorithm == 'PLSR':\n",
        "        selector = PLSRegression(n_components=N_PLSR)\n",
        "        selector.fit(xtrain, ytrain)    \n",
        "        Xtrain_sel = selector.transform(xtrain)\n",
        "        Xtest_sel  = selector.transform(xtest)\n",
        "\n",
        "    # SELECCIÓN + TRANSFORMACIÓN:\n",
        "    elif algorithm == 'SEL_01':\n",
        "        Xtrain_sel, Xtest_sel = selection_01(xtrain, xtest, ytrain)\n",
        "\n",
        "    elif algorithm == 'SEL_02':\n",
        "        Xtrain_sel, Xtest_sel = selection_02(xtrain, xtest, ytrain)\n",
        "\n",
        "    elif algorithm == 'SEL_03':\n",
        "        Xtrain_sel, Xtest_sel = selection_03(xtrain, xtest, ytrain)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid algorithm: {algorithm}\")\n",
        "\n",
        "    return Xtrain_sel, Xtest_sel\n",
        "\n",
        "\n",
        "def load_selected_features(algorithm):\n",
        "    pass\n",
        "\n",
        "\n",
        "def load_classifier(classifier):\n",
        "    if classifier == 'knn':\n",
        "        return KNeighborsClassifier()\n",
        "    elif classifier == 'lda':\n",
        "        return LinearDiscriminantAnalysis()\n",
        "    elif classifier == 'qda':\n",
        "        return QuadraticDiscriminantAnalysis()\n",
        "    elif classifier == 'árboles de decisión':\n",
        "        return DecisionTreeClassifier()\n",
        "    elif classifier == 'random forest':\n",
        "        return RandomForestClassifier()\n",
        "    elif classifier == 'svm lineal':\n",
        "        return SVC(kernel='linear')\n",
        "    elif classifier == 'svm rbf':\n",
        "        return SVC(kernel='rbf')\n",
        "    elif classifier == 'redes neuronales':\n",
        "        return MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid classifier: {classifier}\")\n",
        "\n",
        "\n",
        "def load_trained_classifier():\n",
        "    pass\n",
        "\n",
        "\n",
        "def selection_01(Xtrain, Xtest, ytrain): \n",
        "    ''' clean-->Norm-->SFS--+-------+-->Concatenate-->SFS-->OUT\n",
        "                            |       |\n",
        "                            +--PCA--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    ### SFS 1 ###\n",
        "    print(Xtrain_norm.shape)\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS')\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PCA')\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_sfs1, Xtrain_pca), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_sfs1, Xtest_pca), axis=1)\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_aux, Xtest_aux, ytrain, 'SFS')\n",
        "    #######\n",
        "    return Xtrain_sfs2, Xtest_sfs2\n",
        "\n",
        "\n",
        "def selection_02(Xtrain, Xtest, ytrain):\n",
        "    '''\n",
        "                        +-->PCA---+\n",
        "                        |         |\n",
        "    clean-->Norm-->SFS--+-->ICA---+-->Concatenate-->SFS-->OUT\n",
        "                        |         |\n",
        "                        +-->PLSR--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    ### SFS 1 ###\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS')\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PCA')\n",
        "    ### PLSR ###\n",
        "    Xtrain_plsr, Xtest_plsr = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PLSR')\n",
        "    ### ICA ###\n",
        "    Xtrain_ica, Xtest_ica = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'ICA')\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_pca, Xtrain_ica, Xtrain_plsr), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_pca, Xtest_ica, Xtest_plsr), axis=1)\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_aux, Xtest_aux, ytrain, 'SFS')\n",
        "    #######\n",
        "    return Xtrain_sfs2, Xtest_sfs2\n",
        "\n",
        "\n",
        "def selection_03(Xtrain, Xtest, ytrain):\n",
        "    '''\n",
        "        clean-->Norm-->SFS-+-->EX---+-->PCA-->SFS-->OUT\n",
        "                           |        |\n",
        "                           +-->RFE--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    ### SFS 1 ###\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS')\n",
        "    ### Búsqueda Exhaustiva ###\n",
        "    Xtrain_ex, Xtest_ex = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'EX')\n",
        "    ### RFE ###\n",
        "    Xtrain_rfe, Xtest_rfe = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'RFE')\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_ex, Xtrain_rfe), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_ex, Xtest_rfe), axis=1)\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_aux, Xtest_aux, ytrain, 'PCA')\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_pca, Xtest_pca, ytrain, 'SFS')\n",
        "    return Xtrain_sfs2, Xtest_sfs2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6grN-iWqDGy1"
      },
      "source": [
        "### Cargar imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5gBOG_ia46U",
        "outputId": "16b6a2b4-0094-4a60-dcfa-5485fe8c41b5"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/s4opefjionbdbab/G00.zip\n",
        "!unzip -qq G00.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDobx-xnGYkm"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/zur2wxzcce4qlgf/G01.zip\n",
        "!unzip -qq G01.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0RIDrv8TabcL"
      },
      "source": [
        "## Extracción y selección de caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNdYh_yVabcL"
      },
      "outputs": [],
      "source": [
        "def extraction_main(extraction_models, color_modes, image_set):\n",
        "    # Create the \"features\" folder if it doesn't exist\n",
        "    if not os.path.exists(\"features\"):\n",
        "        os.makedirs(\"features\")\n",
        "    if not os.path.exists(\"y\"):\n",
        "        os.makedirs(\"y\")\n",
        "\n",
        "    # Iterate over extraction models and color modes\n",
        "    for model in extraction_models:\n",
        "        for color_mode in color_modes:\n",
        "            # Extract features\n",
        "            (X, y) = extract_features(color_mode, image_set, model)\n",
        "\n",
        "            # Save features to files\n",
        "            filename = f\"features/X_{image_set}_{model}_{color_mode}.npy\"\n",
        "            y_filename = f\"y/y_{image_set}.npy\"\n",
        "\n",
        "            np.save(filename, X)\n",
        "            np.save(y_filename, y)\n",
        "\n",
        "selection_models = ['SEL_01', 'SEL_02', 'SEL_03']\n",
        "\n",
        "color_modes = [\"gray\", \"blue\", \"red\", \"green\"]\n",
        "\n",
        "def select_main(selection_models, color_modes, image_set):\n",
        "\n",
        "    caract_modes = [\"haralick\", \"hog\", \"zernike\", \"lbp\", \"daisy\"]\n",
        "    \n",
        "    # Create the \"features\" folder if it doesn't exist\n",
        "    if not os.path.exists(\"selected_features\"):\n",
        "        os.makedirs(\"selected_features\")\n",
        "\n",
        "    ytrain = np.load(f'y/y_train.npy')\n",
        "    ytest = np.load(f'y/y_test.npy')\n",
        "\n",
        "    ##CONCATENAR POR COLOR\n",
        "    Xtrain_gray     = np.load(f'features/X_train_haralick_gray.npy')\n",
        "    #Xtest_gray      = np.load(f'features/X_test_haralick_gray.npy')\n",
        "    Xtrain_blue     = np.load(f'features/X_train_haralick_blue.npy')\n",
        "    #Xtest_blue      = np.load(f'features/X_test_haralick_blue.npy')\n",
        "    Xtrain_red      = np.load(f'features/X_train_haralick_red.npy')\n",
        "    #Xtest_red       = np.load(f'features/X_test_haralick_red.npy')\n",
        "    Xtrain_green    = np.load(f'features/X_train_haralick_green.npy')\n",
        "    #Xtest_green     = np.load(f'features/X_test_haralick_green.npy')\n",
        "    for caract in caract_modes[1:]:\n",
        "        if (caract == \"lbp\") | (caract == \"daisy\"):\n",
        "            Xtrain_gray_aux, Xtest_gray_aux = select_features(np.load(f'features/X_train_{caract}_gray.npy'), np.load(f'features/X_test_{caract}_gray.npy'), ytrain, algorithm='PCA') \n",
        "            Xtrain_blue_aux, Xtest_blue_aux = select_features(np.load(f'features/X_train_{caract}_blue.npy'), np.load(f'features/X_test_{caract}_blue.npy'), ytrain, algorithm='PCA')\n",
        "            Xtrain_red_aux, Xtest_red_aux = select_features(np.load(f'features/X_train_{caract}_red.npy'), np.load(f'features/X_test_{caract}_red.npy'), ytrain, algorithm='PCA')\n",
        "            Xtrain_green_aux, Xtest_green_aux = select_features(np.load(f'features/X_train_{caract}_green.npy'), np.load(f'features/X_test_{caract}_green.npy'), ytrain, algorithm='PCA')\n",
        "        else:\n",
        "            Xtrain_gray_aux = np.load(f'features/X_train_{caract}_gray.npy')\n",
        "            Xtest_gray_aux  = np.load(f'features/X_test_{caract}_gray.npy')\n",
        "            Xtrain_blue_aux = np.load(f'features/X_train_{caract}_blue.npy')\n",
        "            Xtest_blue_aux  = np.load(f'features/X_test_{caract}_blue.npy')\n",
        "            Xtrain_red_aux = np.load(f'features/X_train_{caract}_red.npy')\n",
        "            Xtest_red_aux  = np.load(f'features/X_test_{caract}_red.npy')\n",
        "            Xtrain_green_aux = np.load(f'features/X_train_{caract}_green.npy')\n",
        "            Xtest_green_aux  = np.load(f'features/X_test_{caract}_green.npy')\n",
        "\n",
        "\n",
        "        Xtrain_gray     = np.concatenate((Xtrain_gray,  Xtrain_gray_aux), axis=1)\n",
        "        Xtest_gray      = np.concatenate((Xtest_gray,   Xtest_gray_aux), axis=1)\n",
        "        Xtrain_blue     = np.concatenate((Xtrain_blue,  Xtrain_blue_aux), axis=1)\n",
        "        Xtest_blue      = np.concatenate((Xtest_blue,   Xtest_blue_aux), axis=1)\n",
        "        Xtrain_red      = np.concatenate((Xtrain_red,   Xtrain_red_aux), axis=1)\n",
        "        Xtest_red       = np.concatenate((Xtest_red,    Xtest_red_aux), axis=1)\n",
        "        Xtrain_green    = np.concatenate((Xtrain_green, Xtrain_green_aux), axis=1)\n",
        "        Xtest_green     = np.concatenate((Xtest_green,  Xtest_green_aux), axis=1)\n",
        "\n",
        "    ##SELECCIONAR CARACTERISTICAS\n",
        "    for model in selection_models:\n",
        "\n",
        "        print('START SELECTION \\n')\n",
        "        Xtrain_sel_gray, Xtest_sel_gray = select_features(Xtrain_gray, Xtest_gray, ytrain, algorithm=model)\n",
        "        print(f'Selection_gray_{model}')\n",
        "        np.save(f'selected_features/X_train_{model}_gray.npy', Xtrain_sel_gray)\n",
        "        np.save(f'selected_features/X_test_{model}_gray.npy', Xtest_sel_gray)\n",
        "\n",
        "        Xtrain_sel_blue, Xtest_sel_blue = select_features(Xtrain_blue, Xtest_blue, ytrain, algorithm=model)\n",
        "        print(f'Selection_blue_{model}')\n",
        "        np.save(f'selected_features/X_train_{model}_blue.npy', Xtrain_sel_blue)\n",
        "        np.save(f'selected_features/X_test_{model}_blue.npy', Xtest_sel_blue)\n",
        "\n",
        "        Xtrain_sel_red, Xtest_sel_red = select_features(Xtrain_red, Xtest_red, ytrain, algorithm=model)\n",
        "        print(f'Selection_red_{model}')\n",
        "        np.save(f'selected_features/X_train_{model}_red.npy', Xtrain_sel_red)\n",
        "        np.save(f'selected_features/X_test_{model}_red.npy', Xtest_sel_red)\n",
        "\n",
        "        Xtrain_sel_green, Xtest_sel_green = select_features(Xtrain_green, Xtest_green, ytrain, algorithm=model)\n",
        "        print(f'Selection_green_{model}')\n",
        "        np.save(f'selected_features/X_train_{model}_green.npy', Xtrain_sel_green)\n",
        "        np.save(f'selected_features/X_test_{model}_green.npy', Xtest_sel_green)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "xWOs66SSCFq_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n",
            "PCA done\n"
          ]
        }
      ],
      "source": [
        "Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_01_gray.npy')\n",
        "Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_01_gray.npy')\n",
        "Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_01_blue.npy')\n",
        "Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_01_blue.npy')\n",
        "Xtrain_red_aux = np.load(f'selected_features/X_train_SEL_01_red.npy')\n",
        "Xtest_red_aux  = np.load(f'selected_features/X_test_SEL_01_red.npy')\n",
        "Xtrain_green_aux = np.load(f'selected_features/X_train_SEL_01_green.npy')\n",
        "Xtest_green_aux  = np.load(f'selected_features/X_test_SEL_01_green.npy')\n",
        "\n",
        "Xtrain = np.concatenate((Xtrain_gray_aux, Xtrain_blue_aux, Xtrain_red_aux, Xtrain_green_aux), axis=1)\n",
        "Xtest = np.concatenate((Xtest_gray_aux, Xtest_blue_aux, Xtest_red_aux, Xtest_green_aux), axis=1)\n",
        "\n",
        "Xtrain_sel, Xtest_sel = select_features(Xtrain, Xtest, ytrain, algorithm='PCA')\n",
        "\n",
        "np.save(f'selected_features/X_train_SEL_01_all.npy', Xtrain_sel)\n",
        "np.save(f'selected_features/X_test_SEL_01_all.npy', Xtest_sel)\n",
        "\n",
        "Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_02_gray.npy')\n",
        "Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_02_gray.npy')\n",
        "Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_02_blue.npy')\n",
        "Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_02_blue.npy')\n",
        "Xtrain_red_aux = np.load(f'selected_features/X_train_SEL_02_red.npy')\n",
        "Xtest_red_aux  = np.load(f'selected_features/X_test_SEL_02_red.npy')\n",
        "Xtrain_green_aux = np.load(f'selected_features/X_train_SEL_02_green.npy')\n",
        "Xtest_green_aux  = np.load(f'selected_features/X_test_SEL_02_green.npy')\n",
        "\n",
        "Xtrain = np.concatenate((Xtrain_gray_aux, Xtrain_blue_aux, Xtrain_red_aux, Xtrain_green_aux), axis=1)\n",
        "Xtest = np.concatenate((Xtest_gray_aux, Xtest_blue_aux, Xtest_red_aux, Xtest_green_aux), axis=1)\n",
        "\n",
        "Xtrain_sel, Xtest_sel = select_features(Xtrain, Xtest, ytrain, algorithm='PCA')\n",
        "\n",
        "np.save(f'selected_features/X_train_SEL_02_all.npy', Xtrain_sel)\n",
        "np.save(f'selected_features/X_test_SEL_02_all.npy', Xtest_sel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1080, 100)\n",
            "(360, 100)\n",
            "(1080, 100)\n",
            "(360, 100)\n"
          ]
        }
      ],
      "source": [
        "Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_01_gray.npy')\n",
        "Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_01_gray.npy')\n",
        "\n",
        "Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_02_blue.npy')\n",
        "Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_02_blue.npy')\n",
        "\n",
        "print(Xtrain_gray_aux.shape)\n",
        "print(Xtest_gray_aux.shape)\n",
        "print(Xtrain_blue_aux.shape)\n",
        "print(Xtest_blue_aux.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_y248SgabcP"
      },
      "source": [
        "## Clasificación"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### De acá en adelante se pueden ejecutar los modelos 1 y 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## ARCHIVOS CON CARACTERISTICAS SELECCIONADAS\n",
        "\n",
        "!wget https://www.dropbox.com/s/tivfqnxt8cbz3yq/selected.zip\n",
        "!unzip -qq selected.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1vq1gxv4abcP"
      },
      "source": [
        "descargar caracteristicas seleccionadas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "58_8ANIKabcQ"
      },
      "source": [
        "### Ensamble de clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vO29jXRHabcR"
      },
      "outputs": [],
      "source": [
        "def majority_voting_ensemble(models, X_test):\n",
        "    predictions = np.array([model.predict(X_test) for model in models])\n",
        "    majority_vote = mode(predictions, axis=0)\n",
        "    return majority_vote.mode.flatten()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TjLhuqazabcR"
      },
      "source": [
        "## MODELO 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "at7D1MayabcR"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mbNN5vsEabcR"
      },
      "outputs": [],
      "source": [
        "def modelo_1(X_train, y_train):\n",
        "\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "          \n",
        "    # Dividir el conjunto de entrenamiento en entrenamiento y prueba (Hold Out)\n",
        "    X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train, y_train, test_size=4, random_state=42)\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Iterar sobre diferentes modelos y encontrar el que maximice la precisión\n",
        "    for model in models:\n",
        "        # Entrenar el modelo con el conjunto de entrenamiento\n",
        "        model.fit(X_train_1, y_train_1)\n",
        "\n",
        "        # Predecir las etiquetas para el conjunto de prueba\n",
        "        y_pred = model.predict(X_test_1)\n",
        "\n",
        "        # Calcular la precisión del modelo\n",
        "        accuracy = accuracy_score(y_test_1, y_pred)\n",
        "\n",
        "        # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "        model.fit(X_train, y_train)\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "    \n",
        "    # Entregar el mejor modelo encontrado\n",
        "    entregable_modelo_1 = best_model\n",
        "\n",
        "    return models, entregable_modelo_1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4S7unylpabcS"
      },
      "source": [
        "## MODELO 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XnwyRdKQabcS"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RC4ysEONabcS"
      },
      "outputs": [],
      "source": [
        "def model_2(Xtrain, ytrain):\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    # Iterar sobre diferentes modelos y encontrar el que maximice la precisión en cross-val\n",
        "    for model in models:\n",
        "        # Realizar cross-val con 4 folds en las imágenes de grupo 0\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=4)\n",
        "\n",
        "        # Calcular la precisión promedio en cross-val\n",
        "        accuracy = scores.mean()\n",
        "\n",
        "        # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "        model.fit(X_train, y_train)\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    # Entregar el mejor modelo encontrado\n",
        "    entregable_modelo_2 = best_model\n",
        "\n",
        "    return models, entregable_modelo_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = np.load('y/y_train.npy')\n",
        "y_test = np.load('y/y_test.npy')\n",
        "\n",
        "accs_m1 = {}\n",
        "accs_m2 = {}\n",
        "\n",
        "all_files = [\"red\", \"green\", \"blue\", \"gray\"]\n",
        "for n in [1, 2]:\n",
        "    accs_m1[n] = {}\n",
        "    accs_m2[n] = {}\n",
        "    for i in all_files:\n",
        "        X_train = np.load(f'selected_features/X_train_SEL_0{n}_{i}.npy')\n",
        "        X_test = np.load(f'selected_features/X_test_SEL_0{n}_{i}.npy')\n",
        "\n",
        "        ##MODELO 1\n",
        "        models, best_model_1 = modelo_1(X_train, y_train)\n",
        "        y_pred_1 = best_model_1.predict(X_test)\n",
        "        accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
        "        \n",
        "        print(f\"Accuracy model 1: {accuracy_1}\")\n",
        "        accs_m1[n][i] = accuracy_1\n",
        "\n",
        "        y_pred_mv = majority_voting_ensemble(models, X_test)\n",
        "        accuracy_mv = accuracy_score(y_test, y_pred_mv)\n",
        "\n",
        "        print(f\"Accuracy majority voting: {accuracy_mv}\")\n",
        "        accs_m1[n][f'{i}_mv'] = accuracy_mv\n",
        "\n",
        "        ## MODELO 2\n",
        "        models, best_model_2 = model_2(X_train, y_train)\n",
        "        y_pred_2 = best_model_2.predict(X_test)\n",
        "        accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
        "\n",
        "        print(f\"Accuracy model 2: {accuracy_2}\")\n",
        "        accs_m2[n][i] = accuracy_2\n",
        "\n",
        "        y_pred_mv = majority_voting_ensemble(models, X_test)\n",
        "        accuracy_mv = accuracy_score(y_test, y_pred_mv)\n",
        "\n",
        "        print(f\"Accuracy majority voting: {accuracy_mv}\")\n",
        "        accs_m2[n][f'{i}_mv'] = accuracy_mv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: {'red': 0.6611111111111111, 'red_mv': 0.6444444444444445, 'green': 0.6361111111111111, 'green_mv': 0.6333333333333333, 'blue': 0.6222222222222222, 'blue_mv': 0.6083333333333333, 'gray': 0.6416666666666667, 'gray_mv': 0.6222222222222222}, 2: {'red': 0.6611111111111111, 'red_mv': 0.5416666666666666, 'green': 0.6361111111111111, 'green_mv': 0.5111111111111111, 'blue': 0.6222222222222222, 'blue_mv': 0.5138888888888888, 'gray': 0.6444444444444445, 'gray_mv': 0.5361111111111111}}\n",
            "{1: {'red': 0.6611111111111111, 'red_mv': 0.6472222222222223, 'green': 0.6361111111111111, 'green_mv': 0.6388888888888888, 'blue': 0.6222222222222222, 'blue_mv': 0.6083333333333333, 'gray': 0.6416666666666667, 'gray_mv': 0.6305555555555555}, 2: {'red': 0.6611111111111111, 'red_mv': 0.5555555555555556, 'green': 0.6361111111111111, 'green_mv': 0.5166666666666667, 'blue': 0.6222222222222222, 'blue_mv': 0.5083333333333333, 'gray': 0.6444444444444445, 'gray_mv': 0.5333333333333333}}\n"
          ]
        }
      ],
      "source": [
        "print(accs_m1)\n",
        "print(accs_m2)\n",
        "\n",
        "np.save('accs_m1.npy', accs_m1)\n",
        "np.save('accs_m2.npy', accs_m2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the extraction models and color modes\n",
        "extraction_models = [\"lbp\", \"hog\", \"haralick\", \"gabor\", \"glcm\", \"zernike\", \"daisy\"]\n",
        "color_modes = [\"gray\", \"red\", \"green\", \"blue\"]\n",
        "\n",
        "extraction_main(extraction_models, color_modes, \"train\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
