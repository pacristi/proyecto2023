{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VN9CHgR9abcE"
      },
      "source": [
        "# PROYECTO 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud6KEYvHabcH"
      },
      "source": [
        "Descripción proyecto"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "43IO1yccabcI"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install numpy --upgrade\n",
        "%pip install mahotas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5ghE_GnuabcJ",
        "outputId": "cc65cb88-c78d-4de1-f395-a7e92b743d9e"
      },
      "outputs": [],
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Procesamiento de imagenes\n",
        "import cv2\n",
        "\n",
        "# Visualizacion\n",
        "from   tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extraccion/seleccion de caracteristicas, clasificacion, evaluacion\n",
        "from   balu3.fx.geo    import fourierdes, hugeo, flusser, gupta,basicgeo # caracteristicas geometricas?\n",
        "from   balu3.fx.chr    import lbp, haralick, gabor, hog\n",
        "from   balu3.ft.norm   import minmax\n",
        "from   balu3.fs.sel    import jfisher,sfs,clean, exsearch\n",
        "from   balu3.io.misc   import imageload\n",
        "from   balu3.cl.basics import ClassifierKNN\n",
        "from   balu3.ft.trans  import pca\n",
        "from scipy.stats import mode\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.measure import moments\n",
        "from skimage.feature import graycomatrix, daisy, graycoprops\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, RFE, RFECV, mutual_info_classif ## fisher_score, \n",
        "from sklearn.cross_decomposition import PLSRegression \n",
        "\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as mlxsfs\n",
        "from mahotas.features import zernike_moments"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'lbp': 531, 'haralick': 24, 'gabor': 67, 'hog': 9, 'zernike': 25, 'glcm': 4, 'daisy': 768}\n"
          ]
        }
      ],
      "source": [
        "IMG_WIDTH = IMG_HEIGHT = 800 // 1.2\n",
        "\n",
        "# LBP\n",
        "LBP_HDIV = LBP_VDIV = 3\n",
        "LBP_BINS = 59\n",
        "\n",
        "# Haralick\n",
        "HAR_DISTANCE = 3\n",
        "HAR_SIZE = 24\n",
        "\n",
        "# Gabor\n",
        "GAB_ROTATIONS = 8\n",
        "GAB_DILATATIONS = 8\n",
        "\n",
        "# HOG\n",
        "HOG_ORIENTATIONS = 9\n",
        "\n",
        "# Zernike\n",
        "ZER_RADIUS = 30\n",
        "ZER_DEGREE = 8\n",
        "ZER_SIZE = 25\n",
        "\n",
        "# GLCM\n",
        "GLCM_DISTANCES = 1\n",
        "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "GLCM_LEVELS = 4\n",
        "\n",
        "GLCM_SIZE = GLCM_LEVELS\n",
        "\n",
        "# Daisy\n",
        "DAISY_RINGS = 1\n",
        "DAISY_STEP = 150\n",
        "DAISY_RADIUS = 50\n",
        "DAISY_ORIENTATIONS = 8\n",
        "DAISY_HISTOGRAMS = 5\n",
        "DAISY_P = math.ceil((IMG_WIDTH - DAISY_RADIUS * 2) / DAISY_STEP) \n",
        "DAISY_Q = math.ceil((IMG_HEIGHT - DAISY_RADIUS * 2) / DAISY_STEP)\n",
        "DAISY_R = (DAISY_RINGS * DAISY_HISTOGRAMS + 1) * DAISY_ORIENTATIONS\n",
        "\n",
        "# Fetaures\n",
        "features_per_function = {\n",
        "    \"lbp\": LBP_HDIV * LBP_VDIV * LBP_BINS,\n",
        "    \"haralick\": HAR_SIZE,\n",
        "    \"gabor\": GAB_ROTATIONS * GAB_DILATATIONS + 3,\n",
        "    \"hog\": HOG_ORIENTATIONS,\n",
        "    \"zernike\": ZER_SIZE,\n",
        "    \"glcm\": GLCM_SIZE,\n",
        "    \"daisy\": DAISY_P * DAISY_Q * DAISY_R\n",
        "}\n",
        "print(features_per_function)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros Selección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SFS\n",
        "N_SFS = 100\n",
        "\n",
        "# Exhaustive\n",
        "N_EX = 5\n",
        "\n",
        "# RFECV\n",
        "RFECV_STEP = 1\n",
        "RFECV_CV = 5\n",
        "\n",
        "# SBS\n",
        "N_SBS = 100\n",
        "SBS_VERBOSE = 2\n",
        "SBS_CV = 100\n",
        "\n",
        "# PCA\n",
        "N_PCA = 100\n",
        "\n",
        "# ICA\n",
        "N_ICA = 100\n",
        "ICA_RANDOM_STATE = 0\n",
        "\n",
        "# PLSR\n",
        "N_PLSR = 100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfP13LKRabcK"
      },
      "source": [
        "### Funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Si6OrksrabcK"
      },
      "outputs": [],
      "source": [
        "LBP_HDIV = LBP_VDIV = 3\n",
        "DAISY_RINGS = 1\n",
        "\n",
        "\n",
        "def extract_features(color_mode, dataset_type, feature_type):\n",
        "    # Cargar rutas de imágenes y etiquetas según el dataset_type\n",
        "    # ...\n",
        "    K = 90   # <= NUMERO DE CLASES\n",
        "\n",
        "    if dataset_type == 'train':\n",
        "        fpath = \"G00\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 12   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12)\n",
        "\n",
        "    elif dataset_type == 'test':\n",
        "        fpath = \"G01\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 4   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12, 16)\n",
        "\n",
        "    elif dataset_type == 'test2':\n",
        "        fpath = \"G02\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 4   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(16, 20)\n",
        "\n",
        "    dig_clase = 3     # <= NÚMERO DE DÍGITOS POR CLASE\n",
        "    dig_img = 3     # <= NÚMERO DE DÍGITOS POR NÚMERO DE IMAGEN\n",
        "    prefix = \"ID\"     # <= PREFIJO DEL NOMBRE DEL ARCHIVO DE LA IMAGEN\n",
        "    imprefix = fpath + '/' + prefix\n",
        "\n",
        "    # ground truth (clasificacion ideal)\n",
        "    y = np.zeros((K*N), 'int')\n",
        "    features = np.zeros((K*N, features_per_function[feature_type]))\n",
        "\n",
        "    t = 0\n",
        "    for j in tqdm(range(K)):                  # para cada clase\n",
        "        for i in n:                # para cada imagen de la clase\n",
        "            # Lectura de la imagen\n",
        "            clase = j+1\n",
        "            num_img = i+1\n",
        "            img = imageload(imprefix, clase, dig_clase,\n",
        "                            num_img, dig_img)\n",
        "            size = img.shape[0]\n",
        "            new_size = int(size // 1.2)\n",
        "            img = img[size-new_size: new_size,\n",
        "                      size-new_size: new_size]\n",
        "            y[t] = j+1\n",
        "            t = t+1\n",
        "\n",
        "            # Preprocesar las imágenes según el color_mode (blue, red, green, blue)\n",
        "            if color_mode == 'gray':\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            elif color_mode == 'red':\n",
        "                img = img[:, :, 0]\n",
        "            elif color_mode == 'green':\n",
        "                img = img[:, :, 1]\n",
        "            elif color_mode == 'blue':\n",
        "                img = img[:, :, 2]\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid color mode: {color_mode}\")\n",
        "\n",
        "            # Extraer características según el feature_type\n",
        "            if feature_type == 'lbp':\n",
        "                # Aplicar LBP a cada imagen\n",
        "                features[t:, ] = lbp(img, hdiv=LBP_HDIV, vdiv=LBP_VDIV)\n",
        "\n",
        "            elif feature_type == 'haralick':\n",
        "                # Aplicar características de textura Haralick a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Haralick\n",
        "                features[t:, ] = haralick(img, distance=HAR_DISTANCE,)\n",
        "\n",
        "            elif feature_type == 'hog':\n",
        "                # Aplicar HOG a cada imagen\n",
        "                features[t:, ] = hog(img, orientations=HOG_ORIENTATIONS, pixels_per_cell=(\n",
        "                    img.shape[0], img.shape[1]), cells_per_block=(1, 1))\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid feature_type: {feature_type}\")\n",
        "\n",
        "        features = np.array(features)\n",
        "\n",
        "    # Devolver las características extraídas y las etiquetas\n",
        "    return features, y\n",
        "\n",
        "\n",
        "def select_features(xtrain, ytrain, algorithm):\n",
        "    # SELECCIÓN:\n",
        "    if algorithm == 'SFS':\n",
        "        # SFS: Sequential Feature Selection\n",
        "        selector = sfs(xtrain, ytrain, n_features=N_SFS, show=True)\n",
        "\n",
        "    elif algorithm == 'RFE':\n",
        "        # RFE\n",
        "        estimator = SVC(kernel='linear')\n",
        "        selector = RFE(estimator)\n",
        "        selector  = selector.fit(xtrain, ytrain)\n",
        "        selector  = np.nonzero(selector.support_)[0]\n",
        "\n",
        "    # TRANSFORMACIÓN:\n",
        "    elif algorithm == 'PCA':\n",
        "        # PCA: Principal Component Analysis\n",
        "        Xtrain_sel, _, A, Xm, _  = pca(xtrain, n_components=N_PCA)\n",
        "        print('PCA done')\n",
        "\n",
        "    elif algorithm == 'ICA':\n",
        "        # ICA: Independent Component Analysis\n",
        "        selector = FastICA(n_components=N_ICA, random_state=ICA_RANDOM_STATE)\n",
        "        selector.fit(xtrain, ytrain)\n",
        "        Xtrain_sel = selector.transform(xtrain)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid algorithm: {algorithm}\")\n",
        "\n",
        "    return selector\n",
        "\n",
        "def selection_03(Xtrain, ytrain):\n",
        "    '''\n",
        "        clean-->Norm-->RFE---+-->SFS-->OUT\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    #Xtest_clean = Xtest[:,sclean]\n",
        "\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    #Xtest_norm = Xtest_clean * a + b\n",
        "\n",
        "    ### RFE ###\n",
        "    selector_rfe = select_features(Xtrain_norm, ytrain, 'RFE')\n",
        "    Xtrain_rfe = Xtrain_norm[:,selector_rfe]\n",
        "    ### SFS 1 ###\n",
        "    selector_sfs = select_features(Xtrain_rfe, ytrain, 'SFS')\n",
        "\n",
        "    return selector_sfs\n",
        "\n",
        "def load_classifier(classifier):\n",
        "    if classifier == 'knn':\n",
        "        return KNeighborsClassifier()\n",
        "    elif classifier == 'lda':\n",
        "        return LinearDiscriminantAnalysis()\n",
        "    elif classifier == 'qda':\n",
        "        return QuadraticDiscriminantAnalysis()\n",
        "    elif classifier == 'árboles de decisión':\n",
        "        return DecisionTreeClassifier()\n",
        "    elif classifier == 'random forest':\n",
        "        return RandomForestClassifier()\n",
        "    elif classifier == 'svm lineal':\n",
        "        return SVC(kernel='linear')\n",
        "    elif classifier == 'svm rbf':\n",
        "        return SVC(kernel='rbf')\n",
        "    elif classifier == 'redes neuronales':\n",
        "        return MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid classifier: {classifier}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6grN-iWqDGy1"
      },
      "source": [
        "### Cargar imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5gBOG_ia46U",
        "outputId": "16b6a2b4-0094-4a60-dcfa-5485fe8c41b5"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/s4opefjionbdbab/G00.zip\n",
        "!unzip -qq G00.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDobx-xnGYkm"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/zur2wxzcce4qlgf/G01.zip\n",
        "!unzip -qq G01.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0RIDrv8TabcL"
      },
      "source": [
        "## Extracción y selección de caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JNdYh_yVabcL"
      },
      "outputs": [],
      "source": [
        "def extraction_main(extraction_models, color_modes, image_set):\n",
        "    # Create the \"features\" folder if it doesn't exist\n",
        "    if not os.path.exists(\"features\"):\n",
        "        os.makedirs(\"features\")\n",
        "    if not os.path.exists(\"y\"):\n",
        "        os.makedirs(\"y\")\n",
        "\n",
        "    # Iterate over extraction models and color modes\n",
        "    for model in tqdm(extraction_models):\n",
        "        for color_mode in color_modes:\n",
        "            # Extract features\n",
        "            (X, y) = extract_features(color_mode, image_set, model)\n",
        "\n",
        "            # Save features to files\n",
        "            filename = f\"features/X_{image_set}_{model}_{color_mode}.npy\"\n",
        "            y_filename = f\"y/y_{image_set}.npy\"\n",
        "\n",
        "            np.save(filename, X)\n",
        "            np.save(y_filename, y)\n",
        "        \n",
        "def select_main(caract_modes, color_modes):\n",
        "\n",
        "    # Create the \"selected_features\" folder if it doesn't exist\n",
        "    if not os.path.exists(\"selected_features\"):\n",
        "        os.makedirs(\"selected_features\")\n",
        "\n",
        "    y_train = np.load('y/y_train.npy')\n",
        "\n",
        "    for color_mode in color_modes:\n",
        "        X_train_color = []\n",
        "\n",
        "        for caract in caract_modes:\n",
        "            X_train_caract = np.load(f'features/X_train_{caract}_{color_mode}.npy')\n",
        "\n",
        "            X_train_color.append(X_train_caract)\n",
        "\n",
        "        X_train_color = np.concatenate(X_train_color, axis=1) # concatena todas las características de un mismo color\n",
        "\n",
        "        print(f'Start feature selection for {color_mode}')\n",
        "\n",
        "        selector = selection_03(X_train_color, y_train)\n",
        "\n",
        "        np.save(f'selected_features/selector_{color_mode}.npy', selector)\n",
        "\n",
        "        print(f'Selector saved for {color_mode}')\n",
        "\n",
        "    print('Feature selection completed.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_y248SgabcP"
      },
      "source": [
        "## Clasificación"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### De acá en adelante se pueden ejecutar los modelos 1 y 2 "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "58_8ANIKabcQ"
      },
      "source": [
        "### Ensamble de clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vO29jXRHabcR"
      },
      "outputs": [],
      "source": [
        "def majority_voting_ensemble(models, X_test):\n",
        "    predictions = np.array([model.predict(X_test) for model in models])\n",
        "    majority_vote = mode(predictions, axis=0)\n",
        "    return majority_vote.mode.flatten()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TjLhuqazabcR"
      },
      "source": [
        "## MODELO 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "at7D1MayabcR"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mbNN5vsEabcR"
      },
      "outputs": [],
      "source": [
        "def modelo_1(X_train, y_train):\n",
        "\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "          \n",
        "    # Dividir el conjunto de entrenamiento en entrenamiento y prueba (Hold Out)\n",
        "    X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train, y_train, test_size=4, random_state=42)\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Iterar sobre diferentes modelos y encontrar el que maximice la precisión\n",
        "    for model in models:\n",
        "        # Entrenar el modelo con el conjunto de entrenamiento\n",
        "        model.fit(X_train_1, y_train_1)\n",
        "\n",
        "        # Predecir las etiquetas para el conjunto de prueba\n",
        "        y_pred = model.predict(X_test_1)\n",
        "\n",
        "        # Calcular la precisión del modelo\n",
        "        accuracy = accuracy_score(y_test_1, y_pred)\n",
        "\n",
        "        # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "        model.fit(X_train, y_train)\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "    \n",
        "    # Entregar el mejor modelo encontrado\n",
        "    entregable_modelo_1 = best_model\n",
        "\n",
        "    return models, entregable_modelo_1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4S7unylpabcS"
      },
      "source": [
        "## MODELO 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XnwyRdKQabcS"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RC4ysEONabcS"
      },
      "outputs": [],
      "source": [
        "def model_2(X_train, y_train):\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    # Iterar sobre diferentes modelos y encontrar el que maximice la precisión en cross-val\n",
        "    for model in models:\n",
        "        # Realizar cross-val con 4 folds en las imágenes de grupo 0\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=4)\n",
        "\n",
        "        # Calcular la precisión promedio en cross-val\n",
        "        accuracy = scores.mean()\n",
        "\n",
        "        # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "        model.fit(X_train, y_train)\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    # Entregar el mejor modelo encontrado\n",
        "    entregable_modelo_2 = best_model\n",
        "\n",
        "    return models, entregable_modelo_2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODELO 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_3(X, y):\n",
        "\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    n_folds = 5\n",
        "    skf = StratifiedKFold(n_splits=n_folds)\n",
        "\n",
        "    for model in models:\n",
        "      accuracies = np.array([])\n",
        "      for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "            X_train_3, X_test_3 = X[train_index], X[test_index]\n",
        "            y_train_3, y_test_3 = y[train_index], y[test_index]\n",
        "\n",
        "            model.fit(X_train_3, y_train_3)\n",
        "\n",
        "            y_pred = model.predict(X_test_3)\n",
        "\n",
        "            accuracy = accuracy_score(y_test_3, y_pred)\n",
        "            \n",
        "            accuracies = np.append(accuracies, accuracy)\n",
        "      mean_accuracy = np.mean(accuracies)\n",
        "\n",
        "      if mean_accuracy > best_accuracy:\n",
        "            best_accuracy = mean_accuracy\n",
        "            best_model = model\n",
        "\n",
        "      best_model.fit(X, y)\n",
        "\n",
        "    return models, best_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Código para ejecutar tests"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insertar link en la celda de abajo y ejecutar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget <url>\n",
        "!unzip -qq G02.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si no está cargado el G01.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/zur2wxzcce4qlgf/G01.zip\n",
        "!unzip -qq G01.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cargar selected_features, selection_steps e y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/f22yzeacl2y2wbn/selected_features.zip\n",
        "!wget https://www.dropbox.com/s/1fngntbr9bdpy1s/selection01_steps.zip\n",
        "!wget https://www.dropbox.com/s/vk56ogri85txlpt/y.zip\n",
        "\n",
        "!unzip -qq selected_features.zip\n",
        "!unzip -qq selection01_steps.zip\n",
        "!unzip -qq y.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutar celda de abajo para probar, cambiar TEST por \"test\" o \"test2\", siendo G01 Y G02 respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy model 1: 0.35555555555555557\n",
            "Accuracy model 2: 0.5861111111111111\n",
            "Accuracy model 3: 0.5861111111111111\n"
          ]
        }
      ],
      "source": [
        "TEST = \"test\"\n",
        "EXTRACTION_MODS = ['haralick', 'hog', 'lbp']\n",
        "COLOR_MODES = [\"gray\", \"blue\", \"red\", \"green\"]\n",
        "SELECTION_MODELS = ['SEL_01']\n",
        "\n",
        "def test_set(test_set):\n",
        "\n",
        "    # MODO DE EJECUCION\n",
        "    \n",
        "    #extraction_main(EXTRACTION_MODS, COLOR_MODES, test_set)\n",
        "    #select_main(EXTRACTION_MODS, COLOR_MODES)\n",
        "\n",
        "    #selector = np.load(f'selected_features/selector_red.npy')\n",
        "\n",
        "    #print(selector)\n",
        "\n",
        "    X_train_final = []\n",
        "    X_test_final = []\n",
        "    \n",
        "    for color in COLOR_MODES:\n",
        "        selector = np.load(f'selected_features/selector_{color}.npy')\n",
        "\n",
        "        X_train = []\n",
        "        X_test = []\n",
        "\n",
        "        for ext in EXTRACTION_MODS:\n",
        "            X_train.append( np.load(f'features/X_train_{ext}_{color}.npy') )\n",
        "            X_test.append( np.load(f'features/X_{test_set}_{ext}_{color}.npy') )\n",
        "\n",
        "        X_train = np.concatenate(X_train, axis=1)\n",
        "        X_test = np.concatenate(X_test, axis=1)\n",
        "\n",
        "        sclean = clean(X_train)\n",
        "        Xtrain_clean = X_train[:,sclean]\n",
        "        Xtest_clean = X_test[:,sclean]\n",
        "\n",
        "        Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "        Xtest_norm = Xtest_clean * a + b\n",
        "\n",
        "        X_train = X_train[:,selector]\n",
        "        X_test = X_test[:,selector]\n",
        "\n",
        "        X_train_final.append(X_train)\n",
        "        X_test_final.append(X_test)\n",
        "\n",
        "    X_train = np.concatenate(X_train_final, axis=1)\n",
        "    X_test = np.concatenate(X_test_final, axis=1)\n",
        "\n",
        "    y_train = np.load('y/y_train.npy')\n",
        "    y_test = np.load(f'y/y_{test_set}.npy')\n",
        "\n",
        "    ##MODELO 1\n",
        "    models, best_model_1 = modelo_1(X_train, y_train)\n",
        "    y_pred_1 = best_model_1.predict(X_test)\n",
        "    accuracy_m1 = accuracy_score(y_test, y_pred_1)\n",
        "    \n",
        "    print(f\"Accuracy model 1: {accuracy_m1}\")\n",
        "\n",
        "    ## MODELO 2\n",
        "    models, best_model_2 = model_2(X_train, y_train)\n",
        "    y_pred_2 = best_model_2.predict(X_test)\n",
        "    accuracy_m2 = accuracy_score(y_test, y_pred_2)\n",
        "\n",
        "    print(f\"Accuracy model 2: {accuracy_m2}\")\n",
        "    \n",
        "    ## MODELO 3\n",
        "    models, best_model_3 = model_3(X_train, y_train)\n",
        "    y_pred_3 = best_model_3.predict(X_test)\n",
        "    accuracy_m3 = accuracy_score(y_test, y_pred_3)\n",
        "\n",
        "    print(f\"Accuracy model 3: {accuracy_m3}\")\n",
        "    \n",
        "\n",
        "\n",
        "test_set(TEST)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
