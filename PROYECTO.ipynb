{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VN9CHgR9abcE"
      },
      "source": [
        "# PROYECTO 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud6KEYvHabcH"
      },
      "source": [
        "Descripción proyecto"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "43IO1yccabcI"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (1.22.3)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.24.3-cp310-cp310-win_amd64.whl (14.8 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.3\n",
            "    Uninstalling numpy-1.22.3:\n",
            "      Successfully uninstalled numpy-1.22.3\n",
            "  Rolling back uninstall of numpy\n",
            "  Moving to c:\\python310\\lib\\site-packages\\numpy-1.22.3.dist-info\\\n",
            "   from C:\\Python310\\Lib\\site-packages\\~umpy-1.22.3.dist-info\n",
            "  Moving to c:\\python310\\lib\\site-packages\\numpy\\\n",
            "   from C:\\Python310\\Lib\\site-packages\\~umpy\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
            "ERROR: Could not install packages due to an OSError: [WinError 2] El sistema no puede encontrar el archivo especificado: 'c:\\\\Python310\\\\Scripts\\\\f2py.exe' -> 'c:\\\\Python310\\\\Scripts\\\\f2py.exe.deleteme'\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mahotas in c:\\python310\\lib\\site-packages (1.4.13)\n",
            "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from mahotas) (1.22.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "%pip install numpy --upgrade\n",
        "%pip install mahotas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5ghE_GnuabcJ",
        "outputId": "cc65cb88-c78d-4de1-f395-a7e92b743d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(570, 570)\n",
            "(9,)\n"
          ]
        }
      ],
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Procesamiento de imagenes\n",
        "import cv2\n",
        "\n",
        "# Visualizacion\n",
        "from   tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extraccion/seleccion de caracteristicas, clasificacion, evaluacion\n",
        "from   balu3.fx.geo    import fourierdes, hugeo, flusser, gupta,basicgeo # caracteristicas geometricas?\n",
        "from   balu3.fx.chr    import lbp, haralick, gabor, hog\n",
        "from   balu3.ft.norm   import minmax\n",
        "from   balu3.fs.sel    import jfisher,sfs,clean, exsearch\n",
        "from   balu3.io.misc   import imageload\n",
        "from   balu3.cl.basics import ClassifierKNN\n",
        "from   balu3.ft.trans  import pca\n",
        "from scipy.stats import mode\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.measure import moments\n",
        "from skimage.feature import graycomatrix, daisy, graycoprops\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, RFE, RFECV, mutual_info_classif ## fisher_score, \n",
        "from sklearn.cross_decomposition import PLSRegression \n",
        "\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as mlxsfs\n",
        "#from mahotas.features import zernike_moments\n",
        "img = plt.imread(\"G00/ID004_003.png\")\n",
        "img = img[:, :, 2]\n",
        "img = img[400-int(400/1.4) : 400+int(400/1.4), 400-int(400/1.4) : 400+int(400/1.4)]\n",
        "print(img.shape)\n",
        "descs = hog(img, orientations=HOG_ORIENTATIONS, pixels_per_cell=(\n",
        "                    img.shape[0], img.shape[1]), cells_per_block=(1, 1))\n",
        "print(descs.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'lbp': 531, 'haralick': 24, 'gabor': 67, 'hog': 9, 'zernike': 25, 'glcm': 1, 'daisy': 768}\n"
          ]
        }
      ],
      "source": [
        "IMG_WIDTH = IMG_HEIGHT = (400 // 1.4) * 2\n",
        "\n",
        "# LBP\n",
        "LBP_HDIV = LBP_VDIV = 3\n",
        "LBP_BINS = 59\n",
        "\n",
        "# Haralick\n",
        "HAR_DISTANCE = 3\n",
        "HAR_SIZE = 24\n",
        "\n",
        "# Gabor\n",
        "GAB_ROTATIONS = 8\n",
        "GAB_DILATATIONS = 8\n",
        "\n",
        "# HOG\n",
        "HOG_ORIENTATIONS = 9\n",
        "\n",
        "# Zernike\n",
        "ZER_RADIUS = 30\n",
        "ZER_DEGREE = 8\n",
        "ZER_SIZE = 25\n",
        "\n",
        "# GLCM\n",
        "GLCM_DISTANCES = 1\n",
        "GLCM_ANGLES = 0 \n",
        "GLCM_LEVELS = 256\n",
        "\n",
        "GLCM_SIZE = 1\n",
        "\n",
        "# Daisy\n",
        "DAISY_RINGS = 1\n",
        "DAISY_STEP = 150\n",
        "DAISY_RADIUS = 50\n",
        "DAISY_ORIENTATIONS = 8\n",
        "DAISY_HISTOGRAMS = 5\n",
        "DAISY_P = math.ceil((IMG_WIDTH - DAISY_RADIUS * 2) / DAISY_STEP) \n",
        "DAISY_Q = math.ceil((IMG_HEIGHT - DAISY_RADIUS * 2) / DAISY_STEP)\n",
        "DAISY_R = (DAISY_RINGS * DAISY_HISTOGRAMS + 1) * DAISY_ORIENTATIONS\n",
        "\n",
        "# Fetaures\n",
        "features_per_function = {\n",
        "    \"lbp\": LBP_HDIV * LBP_VDIV * LBP_BINS,\n",
        "    \"haralick\": HAR_SIZE,\n",
        "    \"gabor\": GAB_ROTATIONS * GAB_DILATATIONS + 3,\n",
        "    \"hog\": HOG_ORIENTATIONS,\n",
        "    \"zernike\": ZER_SIZE,\n",
        "    \"glcm\": GLCM_SIZE,\n",
        "    \"daisy\": DAISY_P * DAISY_Q * DAISY_R\n",
        "}\n",
        "print(features_per_function)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros Selección"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SFS\n",
        "N_SFS = 100\n",
        "\n",
        "# Exhaustive\n",
        "N_EX = 5\n",
        "\n",
        "# RFECV\n",
        "RFECV_STEP = 1\n",
        "RFECV_CV = 5\n",
        "\n",
        "# SBS\n",
        "N_SBS = 100\n",
        "SBS_VERBOSE = 2\n",
        "SBS_CV = 100\n",
        "\n",
        "# PCA\n",
        "N_PCA = 100\n",
        "\n",
        "# ICA\n",
        "N_ICA = 100\n",
        "ICA_RANDOM_STATE = 0\n",
        "\n",
        "# PLSR\n",
        "N_PLSR = 100"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfP13LKRabcK"
      },
      "source": [
        "### Funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "Si6OrksrabcK"
      },
      "outputs": [],
      "source": [
        "LBP_HDIV = LBP_VDIV = 3\n",
        "DAISY_RINGS = 1\n",
        "\n",
        "\n",
        "def extract_features(color_mode, dataset_type, feature_type):\n",
        "    # Cargar rutas de imágenes y etiquetas según el dataset_type\n",
        "    # ...\n",
        "    K = 90   # <= NUMERO DE CLASES\n",
        "\n",
        "    if dataset_type == 'train':\n",
        "        fpath = \"G00\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 12   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12)\n",
        "\n",
        "    elif dataset_type == 'test':\n",
        "        fpath = \"G01\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 4   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12, 16)\n",
        "\n",
        "    dig_clase = 3     # <= NÚMERO DE DÍGITOS POR CLASE\n",
        "    dig_img = 3     # <= NÚMERO DE DÍGITOS POR NÚMERO DE IMAGEN\n",
        "    prefix = \"ID\"     # <= PREFIJO DEL NOMBRE DEL ARCHIVO DE LA IMAGEN\n",
        "    imprefix = fpath + '/' + prefix\n",
        "\n",
        "    # ground truth (clasificacion ideal)\n",
        "    y = np.zeros((K*N), 'int')\n",
        "    features = np.zeros((K*N, features_per_function[feature_type]))\n",
        "\n",
        "    t = 0\n",
        "    for j in range(K):                  # para cada clase\n",
        "        for i in tqdm(n):                # para cada imagen de la clase\n",
        "            # Lectura de la imagen\n",
        "            clase = j+1\n",
        "            num_img = i+1\n",
        "            img = imageload(imprefix, clase, dig_clase,\n",
        "                            num_img, dig_img, echo='on')\n",
        "            size = img.shape[0]\n",
        "            new_size = int(size/1.4)\n",
        "            img = img[size-new_size: size+new_size,\n",
        "                      size-new_size: size+new_size]\n",
        "            y[t] = j+1\n",
        "            t = t+1\n",
        "\n",
        "            # Preprocesar las imágenes según el color_mode (blue, red, green, blue)\n",
        "            if color_mode == 'blue':\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            elif color_mode == 'red':\n",
        "                img = img[:, :, 0]\n",
        "            elif color_mode == 'green':\n",
        "                img = img[:, :, 1]\n",
        "            elif color_mode == 'blue':\n",
        "                img = img[:, :, 2]\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid color mode: {color_mode}\")\n",
        "\n",
        "            # Extraer características según el feature_type\n",
        "            if feature_type == 'lbp':\n",
        "                # Aplicar LBP a cada imagen\n",
        "                features[t:, ] = lbp(img, hdiv=LBP_HDIV, vdiv=LBP_VDIV)\n",
        "\n",
        "            elif feature_type == 'haralick':\n",
        "                # Aplicar características de textura Haralick a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Haralick\n",
        "                features[t:, ] = haralick(img, distance=HAR_DISTANCE,)\n",
        "\n",
        "            elif feature_type == 'gabor':\n",
        "                # Aplicar filtro de Gabor a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Gabor\n",
        "                features[t:, ] = gabor(\n",
        "                    img, rotations=GAB_ROTATIONS, dilations=GAB_DILATATIONS)\n",
        "\n",
        "            elif feature_type == 'hog':\n",
        "                # Aplicar HOG a cada imagen\n",
        "                features[t:, ] = hog(img, orientations=HOG_ORIENTATIONS, pixels_per_cell=(\n",
        "                    img.shape[0], img.shape[1]), cells_per_block=(1, 1))\n",
        "\n",
        "            elif feature_type == 'zernike':\n",
        "                # Aplicar momentos de Zernike a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Zernike\n",
        "                features[t:, ] = zernike_moments(img, radius=ZER_RADIUS, degree=ZER_DEGREE)\n",
        "\n",
        "            elif feature_type == 'glcm':\n",
        "                img_uint = img.astype(np.uint8)\n",
        "                # Aplicar GLCM (Matriz de co-ocurrencia de niveles de gris) a cada imagen\n",
        "                glcm = bluecomatrix(img_uint, [GLCM_DISTANCES], [GLCM_ANGLES], levels=GLCM_LEVELS)\n",
        "                contrast = bluecoprops(glcm, 'contrast')\n",
        "                # Compute desired GLCM properties (e.g., contrast, energy, correlation, etc.)\n",
        "                features[t:, ] = np.concatenate(contrast)\n",
        "\n",
        "            elif feature_type == 'daisy':\n",
        "                # Aplicar Daisy a cada imagen\n",
        "                features[t:, ] = daisy(img, step=DAISY_STEP, radius=DAISY_RADIUS, rings=DAISY_RINGS,\n",
        "                                    histograms=DAISY_HISTOGRAMS, orientations=DAISY_ORIENTATIONS).flatten()\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid feature_type: {feature_type}\")\n",
        "\n",
        "        features = np.array(features)\n",
        "\n",
        "    # Devolver las características extraídas y las etiquetas\n",
        "    return features, y\n",
        "\n",
        "\n",
        "def load_features(color, set, function):\n",
        "    # !wget https://www.dropbox.com/caracteristicas.npz?dl=0\n",
        "    # !mv caracteristicas.npz?dl=0 caracteristicas.npz\n",
        "\n",
        "    loaded_caracteristicas = np.load('caracteristicas.npz')\n",
        "    y = loaded_caracteristicas['y']\n",
        "    pass\n",
        "\n",
        "\n",
        "def select_features(xtrain, xtest, ytrain, algorithm):\n",
        "    # SELECCIÓN:\n",
        "    if algorithm == 'SFS':\n",
        "        # SFS: Sequential Feature Selection\n",
        "        selector = sfs(xtrain, ytrain, n_features=N_SFS, show=True)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'EX':\n",
        "        # Exhaustive Search\n",
        "        selector = exsearch(xtrain, ytrain, N_EX)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'RFECV':\n",
        "        # Recursive Feature Elimination\n",
        "        estimator = SVC(kernel='linear')\n",
        "        selector = RFECV(estimator, step=RFECV_STEP, cv=5)\n",
        "        selector  = selector.fit(xtrain, ytrain)\n",
        "        selector       = np.nonzero(selector.support_)[0]\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'RFE':\n",
        "        # RFE\n",
        "        estimator = SVC(kernel='linear')\n",
        "        selector = RFE(estimator)\n",
        "        selector  = selector.fit(xtrain, ytrain)\n",
        "        selector  = np.nonzero(selector.support_)[0]\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    elif algorithm == 'SBS':\n",
        "        # SBS\n",
        "        estimator = KNeighborsClassifier(n_neighbors=5)\n",
        "        selector = mlxsfs(estimator, k_features=N_SBS, forward=False, floating=False, verbose=SBS_VERBOSE, scoring='accuracy', cv=SBS_CV)\n",
        "        selector = selector.fit(xtrain, ytrain)\n",
        "        selector = list(selector.k_feature_idx_)\n",
        "        Xtrain_sel = xtrain[:, selector]\n",
        "        Xtest_sel  = xtest[:, selector]\n",
        "\n",
        "    # TRANSFORMACIÓN:\n",
        "    elif algorithm == 'PCA':\n",
        "        # PCA: Principal Component Analysis\n",
        "        Xtrain_sel, _, A, Xm, _  = pca(xtrain, n_components=N_PCA)\n",
        "        Xtest_sel = np.matmul(xtest - Xm, A)\n",
        "        print('PCA done')\n",
        "\n",
        "    elif algorithm == 'ICA':\n",
        "        # ICA: Independent Component Analysis\n",
        "        selector = FastICA(n_components=N_ICA, random_state=ICA_RANDOM_STATE)\n",
        "        selector.fit(xtrain, ytrain)\n",
        "        Xtrain_sel = selector.transform(xtrain)\n",
        "        Xtest_sel = selector.transform(xtest)\n",
        "    \n",
        "    elif algorithm == 'PLSR':\n",
        "        selector = PLSRegression(n_components=N_PLSR)\n",
        "        selector.fit(xtrain, ytrain)    \n",
        "        Xtrain_sel = selector.transform(xtrain)\n",
        "        Xtest_sel  = selector.transform(xtest)\n",
        "\n",
        "    # SELECCIÓN + TRANSFORMACIÓN:\n",
        "    elif algorithm == 'SEL_01':\n",
        "        Xtrain_sel, Xtest_sel = selection_01(xtrain, xtest, ytrain)\n",
        "\n",
        "    elif algorithm == 'SEL_02':\n",
        "        Xtrain_sel, Xtest_sel = selection_02(xtrain, xtest, ytrain)\n",
        "\n",
        "    elif algorithm == 'SEL_03':\n",
        "        Xtrain_sel, Xtest_sel = selection_03(xtrain, xtest, ytrain)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid algorithm: {algorithm}\")\n",
        "\n",
        "    return Xtrain_sel, Xtest_sel\n",
        "\n",
        "\n",
        "def load_selected_features(algorithm):\n",
        "    pass\n",
        "\n",
        "\n",
        "def load_classifier(classifier):\n",
        "    if classifier == 'knn':\n",
        "        return KNeighborsClassifier()\n",
        "    elif classifier == 'lda':\n",
        "        return LinearDiscriminantAnalysis()\n",
        "    elif classifier == 'qda':\n",
        "        return QuadraticDiscriminantAnalysis()\n",
        "    elif classifier == 'árboles de decisión':\n",
        "        return DecisionTreeClassifier()\n",
        "    elif classifier == 'random forest':\n",
        "        return RandomForestClassifier()\n",
        "    elif classifier == 'svm lineal':\n",
        "        return SVC(kernel='linear')\n",
        "    elif classifier == 'svm rbf':\n",
        "        return SVC(kernel='rbf')\n",
        "    elif classifier == 'redes neuronales':\n",
        "        return MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid classifier: {classifier}\")\n",
        "\n",
        "\n",
        "def load_trained_classifier():\n",
        "    pass\n",
        "\n",
        "\n",
        "def selection_01(Xtrain, Xtest, ytrain): \n",
        "    ''' clean-->Norm-->SFS--+-------+-->Concatenate-->SFS-->OUT\n",
        "                            |       |\n",
        "                            +--PCA--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    ### SFS 1 ###\n",
        "    print(Xtrain_norm.shape)\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS')\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PCA')\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_sfs1, Xtrain_pca), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_sfs1, Xtest_pca), axis=1)\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_aux, Xtest_aux, ytrain, 'SFS')\n",
        "    #######\n",
        "    return Xtrain_sfs2, Xtest_sfs2\n",
        "\n",
        "\n",
        "def selection_02(Xtrain, Xtest, ytrain):\n",
        "    '''\n",
        "                        +-->PCA---+\n",
        "                        |         |\n",
        "    clean-->Norm-->SFS--+-->ICA---+-->Concatenate-->SFS-->OUT\n",
        "                        |         |\n",
        "                        +-->PLSR--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    ### SFS 1 ###\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS')\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PCA')\n",
        "    ### PLSR ###\n",
        "    Xtrain_plsr, Xtest_plsr = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'PLSR')\n",
        "    ### ICA ###\n",
        "    Xtrain_ica, Xtest_ica = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'ICA')\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_pca, Xtrain_ica, Xtrain_plsr), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_pca, Xtest_ica, Xtest_plsr), axis=1)\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_aux, Xtest_aux, ytrain, 'SFS')\n",
        "    #######\n",
        "    return Xtrain_sfs2, Xtest_sfs2\n",
        "\n",
        "\n",
        "def selection_03(Xtrain, Xtest, ytrain):\n",
        "    '''\n",
        "        clean-->Norm-->SFS-+-->EX---+-->PCA-->SFS-->OUT\n",
        "                           |        |\n",
        "                           +-->RFE--+\n",
        "    '''\n",
        "    ### Clean ###\n",
        "    sclean = clean(Xtrain)\n",
        "    Xtrain_clean = Xtrain[:,sclean]\n",
        "    Xtest_clean = Xtest[:,sclean]\n",
        "    ### Normalización ###\n",
        "    Xtrain_norm, a, b = minmax(Xtrain_clean)\n",
        "    Xtest_norm = Xtest_clean * a + b\n",
        "    ### SFS 1 ###\n",
        "    Xtrain_sfs1, Xtest_sfs1 = select_features(Xtrain_norm, Xtest_norm, ytrain, 'SFS')\n",
        "    ### Búsqueda Exhaustiva ###\n",
        "    Xtrain_ex, Xtest_ex = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'EX')\n",
        "    ### RFE ###\n",
        "    Xtrain_rfe, Xtest_rfe = select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, 'RFE')\n",
        "    ### Concatenación ###\n",
        "    Xtrain_aux = np.concatenate((Xtrain_ex, Xtrain_rfe), axis=1)\n",
        "    Xtest_aux = np.concatenate((Xtest_ex, Xtest_rfe), axis=1)\n",
        "    ### PCA ###\n",
        "    Xtrain_pca, Xtest_pca = select_features(Xtrain_aux, Xtest_aux, ytrain, 'PCA')\n",
        "    ### SFS 2 ###\n",
        "    Xtrain_sfs2, Xtest_sfs2 = select_features(Xtrain_pca, Xtest_pca, ytrain, 'SFS')\n",
        "    return Xtrain_sfs2, Xtest_sfs2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6grN-iWqDGy1"
      },
      "source": [
        "### Cargar imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5gBOG_ia46U",
        "outputId": "16b6a2b4-0094-4a60-dcfa-5485fe8c41b5"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/s4opefjionbdbab/G00.zip\n",
        "!unzip -qq G00.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDobx-xnGYkm"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/zur2wxzcce4qlgf/G01.zip\n",
        "!unzip -qq G01.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0RIDrv8TabcL"
      },
      "source": [
        "## Extracción de caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "JNdYh_yVabcL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "START SELECTION \n",
            "\n",
            "(1080, 239)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [07:19<00:00, 4.40s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [05:42<00:00, 3.43s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection_gray_SEL_01\n",
            "(1080, 241)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [07:53<00:00, 4.74s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [05:43<00:00, 3.44s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection_blue_SEL_01\n",
            "(1080, 239)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [07:24<00:00, 4.44s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [06:24<00:00, 3.85s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection_red_SEL_01\n",
            "(1080, 240)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [08:13<00:00, 4.94s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [07:02<00:00, 4.23s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection_green_SEL_01\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "START SELECTION \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [08:12<00:00, 4.93s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [10:51<00:00, 6.51s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection_gray_SEL_02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [08:16<00:00, 4.96s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [10:55<00:00, 6.55s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection_blue_SEL_02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [08:11<00:00, 4.92s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [10:31<00:00, 6.32s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection_red_SEL_02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [08:04<00:00, 4.85s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [10:42<00:00, 6.43s/ features] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selection_green_SEL_02\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "PCA done\n",
            "START SELECTION \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Selecting Features: 100%|██████████| 100/100 [07:17<00:00, 4.38s/ features] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[87], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m     Xtest_green     \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((Xtest_green,  Xtest_green_aux), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSTART SELECTION \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m Xtrain_sel_gray, Xtest_sel_gray \u001b[39m=\u001b[39m select_features(Xtrain_gray, Xtest_gray, ytrain, algorithm\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m     60\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSelection_gray_\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mselected_features/X_train_\u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m_gray.npy\u001b[39m\u001b[39m'\u001b[39m, Xtrain_sel_gray)\n",
            "Cell \u001b[1;32mIn[85], line 182\u001b[0m, in \u001b[0;36mselect_features\u001b[1;34m(xtrain, xtest, ytrain, algorithm)\u001b[0m\n\u001b[0;32m    179\u001b[0m     Xtrain_sel, Xtest_sel \u001b[39m=\u001b[39m selection_02(xtrain, xtest, ytrain)\n\u001b[0;32m    181\u001b[0m \u001b[39melif\u001b[39;00m algorithm \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mSEL_03\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 182\u001b[0m     Xtrain_sel, Xtest_sel \u001b[39m=\u001b[39m selection_03(xtrain, xtest, ytrain)\n\u001b[0;32m    184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid algorithm: \u001b[39m\u001b[39m{\u001b[39;00malgorithm\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[85], line 293\u001b[0m, in \u001b[0;36mselection_03\u001b[1;34m(Xtrain, Xtest, ytrain)\u001b[0m\n\u001b[0;32m    291\u001b[0m Xtrain_sfs1, Xtest_sfs1 \u001b[39m=\u001b[39m select_features(Xtrain_norm, Xtest_norm, ytrain, \u001b[39m'\u001b[39m\u001b[39mSFS\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    292\u001b[0m \u001b[39m### Búsqueda Exhaustiva ###\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m Xtrain_ex, Xtest_ex \u001b[39m=\u001b[39m select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, \u001b[39m'\u001b[39;49m\u001b[39mEX\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    294\u001b[0m \u001b[39m### RFE ###\u001b[39;00m\n\u001b[0;32m    295\u001b[0m Xtrain_rfe, Xtest_rfe \u001b[39m=\u001b[39m select_features(Xtrain_sfs1, Xtest_sfs1, ytrain, \u001b[39m'\u001b[39m\u001b[39mRFE\u001b[39m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[1;32mIn[85], line 123\u001b[0m, in \u001b[0;36mselect_features\u001b[1;34m(xtrain, xtest, ytrain, algorithm)\u001b[0m\n\u001b[0;32m    119\u001b[0m     Xtest_sel  \u001b[39m=\u001b[39m xtest[:, selector]\n\u001b[0;32m    121\u001b[0m \u001b[39melif\u001b[39;00m algorithm \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mEX\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    122\u001b[0m     \u001b[39m# Exhaustive Search\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     selector \u001b[39m=\u001b[39m exsearch(xtrain, ytrain, N_EX)\n\u001b[0;32m    124\u001b[0m     Xtrain_sel \u001b[39m=\u001b[39m xtrain[:, selector]\n\u001b[0;32m    125\u001b[0m     Xtest_sel  \u001b[39m=\u001b[39m xtest[:, selector]\n",
            "File \u001b[1;32mc:\\Users\\artur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\balu3\\fs\\sel.py:175\u001b[0m, in \u001b[0;36mexsearch\u001b[1;34m(features, ypred, n_features, method, options, show)\u001b[0m\n\u001b[0;32m    167\u001b[0m     _combinations \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(tqdm\u001b[39m.\u001b[39mtrange(N,\n\u001b[0;32m    168\u001b[0m                                     desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCombinations checked\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    169\u001b[0m                                     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    170\u001b[0m                                     unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m combinations\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m    171\u001b[0m                         _combinations)\n\u001b[0;32m    173\u001b[0m     _combinations \u001b[39m=\u001b[39m (ii \u001b[39mfor\u001b[39;00m _, ii \u001b[39min\u001b[39;00m _combinations)\n\u001b[1;32m--> 175\u001b[0m chosen_feats \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m(_combinations, key\u001b[39m=\u001b[39;49m_calc_score)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(chosen_feats)\n",
            "File \u001b[1;32mc:\\Users\\artur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\balu3\\fs\\sel.py:162\u001b[0m, in \u001b[0;36mexsearch.<locals>._calc_score\u001b[1;34m(ii)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_calc_score\u001b[39m(ii):\n\u001b[0;32m    161\u001b[0m     feats \u001b[39m=\u001b[39m features[:, ii]\n\u001b[1;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m score(feats, ypred, method\u001b[39m=\u001b[39;49mmethod, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n",
            "File \u001b[1;32mc:\\Users\\artur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\balu3\\fs\\sel.py:83\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(features, ypred, method, param)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39m# fisher\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfisher\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mreturn\u001b[39;00m jfisher(features, ypred, p)\n\u001b[0;32m     85\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msp100\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m sp100(features, ypred)\n",
            "File \u001b[1;32mc:\\Users\\artur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\balu3\\fs\\sel.py:28\u001b[0m, in \u001b[0;36mjfisher\u001b[1;34m(features, ypred, p)\u001b[0m\n\u001b[0;32m     26\u001b[0m ii \u001b[39m=\u001b[39m (norm \u001b[39m==\u001b[39m k)                                   \u001b[39m# indices from class k\u001b[39;00m\n\u001b[0;32m     27\u001b[0m class_features \u001b[39m=\u001b[39m features[ii,:]                    \u001b[39m# samples of class k\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m class_mean \u001b[39m=\u001b[39m class_features\u001b[39m.\u001b[39;49mmean(\u001b[39m0\u001b[39;49m)                \u001b[39m# centroid of class k \u001b[39;00m\n\u001b[0;32m     29\u001b[0m class_cov \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcov(class_features, rowvar\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)   \u001b[39m# covariance of class k\u001b[39;00m\n\u001b[0;32m     31\u001b[0m cov_w \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m p[k] \u001b[39m*\u001b[39m class_cov                          \u001b[39m# within-class covariance\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\artur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:164\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m         \u001b[39mreturn\u001b[39;00m _clip_dep_invoke_with_casting(\n\u001b[0;32m    162\u001b[0m             um\u001b[39m.\u001b[39mclip, a, \u001b[39mmin\u001b[39m, \u001b[39mmax\u001b[39m, out\u001b[39m=\u001b[39mout, casting\u001b[39m=\u001b[39mcasting, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mean\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    165\u001b[0m     arr \u001b[39m=\u001b[39m asanyarray(a)\n\u001b[0;32m    167\u001b[0m     is_float16_result \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Define the extraction models and color modes\n",
        "# extraction_models = [\"lbp\", \"hog\", \"haralick\", \"gabor\", \"glcm\", \"zernike\", \"daisy\"]\n",
        "# color_modes = [\"gray\", \"red\", \"green\", \"blue\"]\n",
        "\n",
        "extraction_models = [\"gabor\"]\n",
        "color_modes = [\"green\"]\n",
        "\n",
        "# Create the \"features\" folder if it doesn't exist\n",
        "if not os.path.exists(\"features\"):\n",
        "    os.makedirs(\"features\")\n",
        "\n",
        "# Iterate over extraction models and color modes\n",
        "for model in extraction_models:\n",
        "    for color_mode in color_modes:\n",
        "        # Extract features\n",
        "        (X_train, y_train) = extract_features(color_mode, \"train\", model)\n",
        "        (X_test, y_test) = extract_features(color_mode, \"test\", model)\n",
        "\n",
        "        # Save features to files\n",
        "        train_filename = f\"features/X_train_{model}_{color_mode}.npy\"\n",
        "        test_filename = f\"features/X_test_{model}_{color_mode}.npy\"\n",
        "selection_models = ['SEL_01', 'SEL_02', 'SEL_03']\n",
        "# caract_modes = [\"daisy\", \"haralick\", \"hog\", \"lbp\", \"zernike\"]\n",
        "caract_modes = [\"haralick\", \"hog\", \"zernike\", \"lbp\", \"daisy\"]\n",
        "\n",
        "color_modes = [\"gray\", \"blue\", \"red\", \"green\"]\n",
        "\n",
        "# Create the \"features\" folder if it doesn't exist\n",
        "if not os.path.exists(\"selected_features\"):\n",
        "    os.makedirs(\"selected_features\")\n",
        "\n",
        "ytrain = np.load(f'y/y_train.npy')\n",
        "ytest = np.load(f'y/y_test.npy')\n",
        "for model in selection_models:\n",
        "        \n",
        "    # Xtrain_gray     = np.load(f'features/X_train_daisy_gray.npy')\n",
        "    # Xtest_gray      = np.load(f'features/X_test_daisy_gray.npy')\n",
        "    # Xtrain_blue     = np.load(f'features/X_train_daisy_blue.npy')\n",
        "    # Xtest_blue      = np.load(f'features/X_test_daisy_blue.npy')\n",
        "    # Xtrain_red      = np.load(f'features/X_train_daisy_red.npy')\n",
        "    # Xtest_red       = np.load(f'features/X_test_daisy_red.npy')\n",
        "    # Xtrain_green    = np.load(f'features/X_train_daisy_green.npy')\n",
        "    # Xtest_green     = np.load(f'features/X_test_daisy_green.npy')\n",
        "    Xtrain_gray     = np.load(f'features/X_train_haralick_gray.npy')\n",
        "    Xtest_gray      = np.load(f'features/X_test_haralick_gray.npy')\n",
        "    Xtrain_blue     = np.load(f'features/X_train_haralick_blue.npy')\n",
        "    Xtest_blue      = np.load(f'features/X_test_haralick_blue.npy')\n",
        "    Xtrain_red      = np.load(f'features/X_train_haralick_red.npy')\n",
        "    Xtest_red       = np.load(f'features/X_test_haralick_red.npy')\n",
        "    Xtrain_green    = np.load(f'features/X_train_haralick_green.npy')\n",
        "    Xtest_green     = np.load(f'features/X_test_haralick_green.npy')\n",
        "    for caract in caract_modes[1:]:\n",
        "        if (caract == \"lbp\") | (caract == \"daisy\"):\n",
        "            Xtrain_gray_aux, Xtest_gray_aux = select_features(np.load(f'features/X_train_{caract}_gray.npy'), np.load(f'features/X_test_{caract}_gray.npy'), ytrain, algorithm='PCA') \n",
        "            Xtrain_blue_aux, Xtest_blue_aux = select_features(np.load(f'features/X_train_{caract}_blue.npy'), np.load(f'features/X_test_{caract}_blue.npy'), ytrain, algorithm='PCA')\n",
        "            Xtrain_red_aux, Xtest_red_aux = select_features(np.load(f'features/X_train_{caract}_red.npy'), np.load(f'features/X_test_{caract}_red.npy'), ytrain, algorithm='PCA')\n",
        "            Xtrain_green_aux, Xtest_green_aux = select_features(np.load(f'features/X_train_{caract}_green.npy'), np.load(f'features/X_test_{caract}_green.npy'), ytrain, algorithm='PCA')\n",
        "        else:\n",
        "            Xtrain_gray_aux = np.load(f'features/X_train_{caract}_gray.npy')\n",
        "            Xtest_gray_aux  = np.load(f'features/X_test_{caract}_gray.npy')\n",
        "            Xtrain_blue_aux = np.load(f'features/X_train_{caract}_blue.npy')\n",
        "            Xtest_blue_aux  = np.load(f'features/X_test_{caract}_blue.npy')\n",
        "            Xtrain_red_aux = np.load(f'features/X_train_{caract}_red.npy')\n",
        "            Xtest_red_aux  = np.load(f'features/X_test_{caract}_red.npy')\n",
        "            Xtrain_green_aux = np.load(f'features/X_train_{caract}_green.npy')\n",
        "            Xtest_green_aux  = np.load(f'features/X_test_{caract}_green.npy')\n",
        "\n",
        "\n",
        "        Xtrain_gray     = np.concatenate((Xtrain_gray,  Xtrain_gray_aux), axis=1)\n",
        "        Xtest_gray      = np.concatenate((Xtest_gray,   Xtest_gray_aux), axis=1)\n",
        "        Xtrain_blue     = np.concatenate((Xtrain_blue,  Xtrain_blue_aux), axis=1)\n",
        "        Xtest_blue      = np.concatenate((Xtest_blue,   Xtest_blue_aux), axis=1)\n",
        "        Xtrain_red      = np.concatenate((Xtrain_red,   Xtrain_red_aux), axis=1)\n",
        "        Xtest_red       = np.concatenate((Xtest_red,    Xtest_red_aux), axis=1)\n",
        "        Xtrain_green    = np.concatenate((Xtrain_green, Xtrain_green_aux), axis=1)\n",
        "        Xtest_green     = np.concatenate((Xtest_green,  Xtest_green_aux), axis=1)\n",
        "\n",
        "    print('START SELECTION \\n')\n",
        "    Xtrain_sel_gray, Xtest_sel_gray = select_features(Xtrain_gray, Xtest_gray, ytrain, algorithm=model)\n",
        "    print(f'Selection_gray_{model}')\n",
        "    np.save(f'selected_features/X_train_{model}_gray.npy', Xtrain_sel_gray)\n",
        "    np.save(f'selected_features/X_test_{model}_gray.npy', Xtest_sel_gray)\n",
        "\n",
        "    Xtrain_sel_blue, Xtest_sel_blue = select_features(Xtrain_blue, Xtest_blue, ytrain, algorithm=model)\n",
        "    print(f'Selection_blue_{model}')\n",
        "    np.save(f'selected_features/X_train_{model}_blue.npy', Xtrain_sel_blue)\n",
        "    np.save(f'selected_features/X_test_{model}_blue.npy', Xtest_sel_blue)\n",
        "\n",
        "    Xtrain_sel_red, Xtest_sel_red = select_features(Xtrain_red, Xtest_red, ytrain, algorithm=model)\n",
        "    print(f'Selection_red_{model}')\n",
        "    np.save(f'selected_features/X_train_{model}_red.npy', Xtrain_sel_red)\n",
        "    np.save(f'selected_features/X_test_{model}_red.npy', Xtest_sel_red)\n",
        "\n",
        "    Xtrain_sel_green, Xtest_sel_green = select_features(Xtrain_green, Xtest_green, ytrain, algorithm=model)\n",
        "    print(f'Selection_green_{model}')\n",
        "    np.save(f'selected_features/X_train_{model}_green.npy', Xtrain_sel_green)\n",
        "    np.save(f'selected_features/X_test_{model}_green.npy', Xtest_sel_green)\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "xWOs66SSCFq_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PCA done\n",
            "PCA done\n"
          ]
        }
      ],
      "source": [
        "Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_01_gray.npy')\n",
        "Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_01_gray.npy')\n",
        "Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_01_blue.npy')\n",
        "Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_01_blue.npy')\n",
        "Xtrain_red_aux = np.load(f'selected_features/X_train_SEL_01_red.npy')\n",
        "Xtest_red_aux  = np.load(f'selected_features/X_test_SEL_01_red.npy')\n",
        "Xtrain_green_aux = np.load(f'selected_features/X_train_SEL_01_green.npy')\n",
        "Xtest_green_aux  = np.load(f'selected_features/X_test_SEL_01_green.npy')\n",
        "\n",
        "Xtrain = np.concatenate((Xtrain_gray_aux, Xtrain_blue_aux, Xtrain_red_aux, Xtrain_green_aux), axis=1)\n",
        "Xtest = np.concatenate((Xtest_gray_aux, Xtest_blue_aux, Xtest_red_aux, Xtest_green_aux), axis=1)\n",
        "\n",
        "Xtrain_sel, Xtest_sel = select_features(Xtrain, Xtest, ytrain, algorithm='PCA')\n",
        "\n",
        "np.save(f'selected_features/X_train_SEL_01_all.npy', Xtrain_sel)\n",
        "np.save(f'selected_features/X_test_SEL_01_all.npy', Xtest_sel)\n",
        "\n",
        "Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_02_gray.npy')\n",
        "Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_02_gray.npy')\n",
        "Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_02_blue.npy')\n",
        "Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_02_blue.npy')\n",
        "Xtrain_red_aux = np.load(f'selected_features/X_train_SEL_02_red.npy')\n",
        "Xtest_red_aux  = np.load(f'selected_features/X_test_SEL_02_red.npy')\n",
        "Xtrain_green_aux = np.load(f'selected_features/X_train_SEL_02_green.npy')\n",
        "Xtest_green_aux  = np.load(f'selected_features/X_test_SEL_02_green.npy')\n",
        "\n",
        "Xtrain = np.concatenate((Xtrain_gray_aux, Xtrain_blue_aux, Xtrain_red_aux, Xtrain_green_aux), axis=1)\n",
        "Xtest = np.concatenate((Xtest_gray_aux, Xtest_blue_aux, Xtest_red_aux, Xtest_green_aux), axis=1)\n",
        "\n",
        "Xtrain_sel, Xtest_sel = select_features(Xtrain, Xtest, ytrain, algorithm='PCA')\n",
        "\n",
        "np.save(f'selected_features/X_train_SEL_02_all.npy', Xtrain_sel)\n",
        "np.save(f'selected_features/X_test_SEL_02_all.npy', Xtest_sel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1080, 100)\n",
            "(360, 100)\n",
            "(1080, 100)\n",
            "(360, 100)\n"
          ]
        }
      ],
      "source": [
        "Xtrain_gray_aux = np.load(f'selected_features/X_train_SEL_01_gray.npy')\n",
        "Xtest_gray_aux  = np.load(f'selected_features/X_test_SEL_01_gray.npy')\n",
        "\n",
        "Xtrain_blue_aux = np.load(f'selected_features/X_train_SEL_02_blue.npy')\n",
        "Xtest_blue_aux  = np.load(f'selected_features/X_test_SEL_02_blue.npy')\n",
        "\n",
        "print(Xtrain_gray_aux.shape)\n",
        "print(Xtest_gray_aux.shape)\n",
        "print(Xtrain_blue_aux.shape)\n",
        "print(Xtest_blue_aux.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aYab7JhKabcM"
      },
      "source": [
        "### Guardar en un archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCZBNf0pabcN"
      },
      "outputs": [],
      "source": [
        "np.savez('caracteristicas.npz', y=ytrain)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H5-sRdm3abcN"
      },
      "source": [
        "## Selección de caracteristicas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p1ijFqTpabcO"
      },
      "source": [
        "Descargar caracteristicas desde el archivo y cargarlas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "QISKp5OAabcO"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'features/y_test.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[58], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mfeatures/X_test_lbp_gray.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mfeatures/X_train_lbp_gray.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mfeatures/y_test.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mfeatures/y_train.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m Xtrain_sel, Xtest_sel \u001b[39m=\u001b[39m select_features(X_train, X_test, y_train, algorithm\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSFS\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\artur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features/y_test.npy'"
          ]
        }
      ],
      "source": [
        "X_test = np.load('features/X_test_lbp_gray.npy')\n",
        "X_train = np.load('features/X_train_lbp_gray.npy')\n",
        "y_test = np.load('features/y_test.npy')\n",
        "y_train = np.load('features/y_train.npy')\n",
        "\n",
        "Xtrain_sel, Xtest_sel = select_features(X_train, X_test, y_train, algorithm='SFS')\n",
        "\n",
        "# Define the extraction models and color modes\n",
        "selection_models = [\"\", \"hog\", \"haralick\", \"gabor\", \"glcm\", \"zernike\", \"daisy\"]\n",
        "color_modes = [\"gray\", \"red\", \"green\", \"blue\"]\n",
        "\n",
        "# Create the \"features\" folder if it doesn't exist\n",
        "if not os.path.exists(\"features\"):\n",
        "    os.makedirs(\"features\")\n",
        "\n",
        "# Iterate over extraction models and color modes\n",
        "for model in extraction_models:\n",
        "    for color_mode in color_modes:\n",
        "        # Extract features\n",
        "        (X_train, y_train) = extract_features(color_mode, \"train\", model)\n",
        "        (X_test, y_test) = extract_features(color_mode, \"test\", model)\n",
        "\n",
        "        # Save features to files\n",
        "        train_filename = f\"features/X_train_{model}_{color_mode}.npy\"\n",
        "        test_filename = f\"features/X_test_{model}_{color_mode}.npy\"\n",
        "\n",
        "        np.save(train_filename, X_train)\n",
        "        np.save(test_filename, X_test)\n",
        "\n",
        "        print(f\"Features saved for {model} - {color_mode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.000e+00, 0.000e+00, 0.000e+00, ..., 0.000e+00, 0.000e+00,\n",
              "        0.000e+00],\n",
              "       [1.130e+02, 1.990e+02, 3.000e+00, ..., 6.400e+01, 3.071e+03,\n",
              "        1.315e+03],\n",
              "       [3.400e+02, 2.910e+02, 6.000e+00, ..., 2.070e+02, 1.686e+03,\n",
              "        1.226e+03],\n",
              "       ...,\n",
              "       [2.230e+02, 1.980e+02, 1.100e+01, ..., 1.290e+02, 2.214e+03,\n",
              "        1.639e+03],\n",
              "       [6.450e+02, 3.610e+02, 2.300e+01, ..., 3.130e+02, 1.990e+03,\n",
              "        2.692e+03],\n",
              "       [6.540e+02, 3.390e+02, 3.100e+01, ..., 1.610e+02, 2.395e+03,\n",
              "        2.470e+03]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F1AQ1JMrabcO"
      },
      "source": [
        "Preprocesamiento de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4dbDyRpabcO"
      },
      "outputs": [],
      "source": [
        "xsel = select_features(X_train, y_train, algorithm='PCA')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W0C9qJFqabcP"
      },
      "source": [
        "Seleccionar caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-07V7G-abcP",
        "outputId": "f7fe9ab4-5ccf-466c-f74e-081b523d5ba0"
      },
      "outputs": [],
      "source": [
        "X1 = np.concatenate((X_train_lbp_gray,X_train_lbp_red),axis=1)\n",
        "X2 = np.concatenate((X_test_lbp_gray ,X_test_lbp_red),axis=1)\n",
        "sel = select_features(X1,ytrain,algorithm='PCA')\n",
        "X1_sel = X1[:,sel]\n",
        "X2_sel = X2[:,sel]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn-RlV5WabcP"
      },
      "source": [
        "guardar caracteristicas seleccionadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eIuIHPGabcP"
      },
      "outputs": [],
      "source": [
        "np.savez('caracteristicas_seleccionadas.npz', y=y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_y248SgabcP"
      },
      "source": [
        "## Clasificación"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1vq1gxv4abcP"
      },
      "source": [
        "descargar caracteristicas seleccionadas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "58_8ANIKabcQ"
      },
      "source": [
        "### Ensamble de clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO29jXRHabcR"
      },
      "outputs": [],
      "source": [
        "def majority_voting_ensemble(models, X_test):\n",
        "    predictions = np.array([model.predict(X_test) for model in models])\n",
        "    majority_vote = mode(predictions, axis=0)\n",
        "    return majority_vote.mode.flatten()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TjLhuqazabcR"
      },
      "source": [
        "## MODELO 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "at7D1MayabcR"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mbNN5vsEabcR"
      },
      "outputs": [],
      "source": [
        "def modelo_1(X_train, y_train):\n",
        "\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "          \n",
        "    # Dividir el conjunto de entrenamiento en entrenamiento y prueba (Hold Out)\n",
        "    X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_train, y_train, test_size=4, random_state=42)\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Iterar sobre diferentes modelos y encontrar el que maximice la precisión\n",
        "    for model in models:\n",
        "        # Entrenar el modelo con el conjunto de entrenamiento\n",
        "        model.fit(X_train_1, y_train_1)\n",
        "\n",
        "        # Predecir las etiquetas para el conjunto de prueba\n",
        "        y_pred = model.predict(X_test_1)\n",
        "\n",
        "        # Calcular la precisión del modelo\n",
        "        accuracy = accuracy_score(y_test_1, y_pred)\n",
        "\n",
        "        # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    # Reentrenar el mejor modelo con todas las imágenes de grupo 0\n",
        "    best_model.fit(X_train, y_train)\n",
        "\n",
        "    # Entregar el mejor modelo encontrado\n",
        "    entregable_modelo_1 = best_model\n",
        "\n",
        "    return entregable_modelo_1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4S7unylpabcS"
      },
      "source": [
        "## MODELO 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XnwyRdKQabcS"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RC4ysEONabcS"
      },
      "outputs": [],
      "source": [
        "def model_2(Xtrain, ytrain):\n",
        "    models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "    \n",
        "    best_model = None\n",
        "    best_accuracy = 0.0\n",
        "    # Iterar sobre diferentes modelos y encontrar el que maximice la precisión en cross-val\n",
        "    for model in models:\n",
        "        # Realizar cross-val con 4 folds en las imágenes de grupo 0\n",
        "        scores = cross_val_score(model, X_train, y_train, cv=4)\n",
        "\n",
        "        # Calcular la precisión promedio en cross-val\n",
        "        accuracy = scores.mean()\n",
        "\n",
        "        # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model = model\n",
        "\n",
        "    # Reentrenar el mejor modelo con todas las imágenes de grupo 0\n",
        "    best_model.fit(X_train, y_train)\n",
        "\n",
        "    # Entregar el mejor modelo encontrado\n",
        "    entregable_modelo_2 = best_model\n",
        "\n",
        "    return entregable_modelo_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy model 1: 0.6611111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7444444444444445\n",
            "Accuracy model 2: 0.6611111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy model 1: 0.6361111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7518518518518519\n",
            "Accuracy model 2: 0.6361111111111111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy model 1: 0.6222222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7453703703703703\n",
            "Accuracy model 2: 0.6222222222222222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy model 1: 0.6416666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "c:\\Python310\\lib\\site-packages\\sklearn\\discriminant_analysis.py:887: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7537037037037038\n",
            "Accuracy model 2: 0.6416666666666667\n"
          ]
        }
      ],
      "source": [
        "y_train = np.load('y_train.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "\n",
        "# current_directory = os.getcwd()\n",
        "# all_files = os.listdir(current_directory + '/selected_features')\n",
        "all_files = [\"red\", \"green\", \"blue\", \"gray\"]\n",
        "\n",
        "for i in all_files:\n",
        "    X_train = np.load('selected_features/X_train_SEL_01_' + i + '.npy')\n",
        "    X_test = np.load('selected_features/X_test_SEL_01_' + i + '.npy')\n",
        "\n",
        "    ##MODELO 1\n",
        "    best_model_1 = modelo_1(X_train, y_train)\n",
        "    y_pred_1 = best_model_1.predict(X_test)\n",
        "    accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
        "\n",
        "    print(f\"Accuracy model 1: {accuracy_1}\")\n",
        "\n",
        "    ## MODELO 2\n",
        "    best_model_2 = model_2(X_train, y_train)\n",
        "    y_pred_2 = best_model_2.predict(X_test)\n",
        "    accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
        "\n",
        "    print(f\"Accuracy model 2: {accuracy_2}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
