{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VN9CHgR9abcE"
      },
      "source": [
        "# PROYECTO 2023"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud6KEYvHabcH"
      },
      "source": [
        "Descripción proyecto"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "43IO1yccabcI"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install numpy --upgrade\n",
        "%pip install mahotas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "5ghE_GnuabcJ",
        "outputId": "cc65cb88-c78d-4de1-f395-a7e92b743d9e"
      },
      "outputs": [],
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Procesamiento de imagenes\n",
        "import cv2\n",
        "\n",
        "# Visualizacion\n",
        "from   tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extraccion/seleccion de caracteristicas, clasificacion, evaluacion\n",
        "from   balu3.fx.geo    import fourierdes, hugeo, flusser, gupta,basicgeo # caracteristicas geometricas?\n",
        "from   balu3.fx.chr    import lbp, haralick, gabor, hog\n",
        "from   balu3.ft.norm   import minmax\n",
        "from   balu3.fs.sel    import jfisher,sfs,clean\n",
        "from   balu3.io.misc   import imageload\n",
        "from   balu3.cl.basics import ClassifierKNN\n",
        "from scipy.stats import mode\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from skimage.measure import moments\n",
        "from skimage.feature import graycomatrix, daisy, graycoprops\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest, RFE, mutual_info_classif ## fisher_score, \n",
        "from mahotas.features import zernike_moments\n",
        "img = plt.imread(\"G00/ID004_003.png\")\n",
        "img = img[:, :, 2]\n",
        "img = img[400-int(400/1.4) : 400+int(400/1.4), 400-int(400/1.4) : 400+int(400/1.4)]\n",
        "print(img.shape)\n",
        "descs = hog(img, orientations=HOG_ORIENTATIONS, pixels_per_cell=(\n",
        "                    img.shape[0], img.shape[1]), cells_per_block=(1, 1))\n",
        "\n",
        "print(descs.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Parámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "IMG_WIDTH = IMG_HEIGHT = (400 // 1.4) * 2\n",
        "\n",
        "# LBP\n",
        "LBP_HDIV = LBP_VDIV = 3\n",
        "LBP_BINS = 59\n",
        "\n",
        "# Haralick\n",
        "HAR_DISTANCE = 3\n",
        "HAR_SIZE = 24\n",
        "\n",
        "# Gabor\n",
        "GAB_ROTATIONS = 8\n",
        "GAB_DILATATIONS = 8\n",
        "\n",
        "# HOG\n",
        "HOG_ORIENTATIONS = 9\n",
        "\n",
        "# Zernike\n",
        "ZER_RADIUS = 30\n",
        "ZER_DEGREE = 8\n",
        "ZER_SIZE = 25\n",
        "\n",
        "# GLCM\n",
        "GLCM_DISTANCES = 1\n",
        "GLCM_ANGLES = 0 \n",
        "GLCM_LEVELS = 256\n",
        "\n",
        "GLCM_SIZE = 1\n",
        "\n",
        "# Daisy\n",
        "DAISY_RINGS = 1\n",
        "DAISY_STEP = 150\n",
        "DAISY_RADIUS = 50\n",
        "DAISY_ORIENTATIONS = 8\n",
        "DAISY_HISTOGRAMS = 5\n",
        "DAISY_P = math.ceil((IMG_WIDTH - DAISY_RADIUS * 2) / DAISY_STEP) \n",
        "DAISY_Q = math.ceil((IMG_HEIGHT - DAISY_RADIUS * 2) / DAISY_STEP)\n",
        "DAISY_R = (DAISY_RINGS * DAISY_HISTOGRAMS + 1) * DAISY_ORIENTATIONS\n",
        "\n",
        "# Fetaures\n",
        "features_per_function = {\n",
        "    \"lbp\": LBP_HDIV * LBP_VDIV * LBP_BINS,\n",
        "    \"haralick\": HAR_SIZE,\n",
        "    \"gabor\": GAB_ROTATIONS * GAB_DILATATIONS + 3,\n",
        "    \"hog\": HOG_ORIENTATIONS,\n",
        "    \"zernike\": ZER_SIZE,\n",
        "    \"glcm\": GLCM_SIZE,\n",
        "    \"daisy\": DAISY_P * DAISY_Q * DAISY_R\n",
        "}\n",
        "print(features_per_function)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xfP13LKRabcK"
      },
      "source": [
        "### Funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si6OrksrabcK"
      },
      "outputs": [],
      "source": [
        "LBP_HDIV = LBP_VDIV = 3\n",
        "DAISY_RINGS = 1\n",
        "\n",
        "\n",
        "def extract_features(color_mode, dataset_type, feature_type):\n",
        "    # Cargar rutas de imágenes y etiquetas según el dataset_type\n",
        "    # ...\n",
        "    K = 90   # <= NUMERO DE CLASES\n",
        "\n",
        "    if dataset_type == 'train':\n",
        "        fpath = \"G00\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 12   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12)\n",
        "\n",
        "    elif dataset_type == 'test':\n",
        "        fpath = \"G01\"     # <= DIRERCTORIO DE LA BASE DE DATOS\n",
        "        N = 4   # <= NUMERO DE IMAGENES POR CLASE\n",
        "        n = range(12, 16)\n",
        "\n",
        "    dig_clase = 3     # <= NÚMERO DE DÍGITOS POR CLASE\n",
        "    dig_img = 3     # <= NÚMERO DE DÍGITOS POR NÚMERO DE IMAGEN\n",
        "    prefix = \"ID\"     # <= PREFIJO DEL NOMBRE DEL ARCHIVO DE LA IMAGEN\n",
        "    imprefix = fpath + '/' + prefix\n",
        "\n",
        "    # ground truth (clasificacion ideal)\n",
        "    y = np.zeros((K*N), 'int')\n",
        "    features = np.zeros((K*N, features_per_function[feature_type]))\n",
        "\n",
        "    t = 0\n",
        "    for j in range(K):                  # para cada clase\n",
        "        for i in tqdm(n):                # para cada imagen de la clase\n",
        "            # Lectura de la imagen\n",
        "            clase = j+1\n",
        "            num_img = i+1\n",
        "            img = imageload(imprefix, clase, dig_clase,\n",
        "                            num_img, dig_img, echo='on')\n",
        "            size = img.shape[0]\n",
        "            new_size = int(size/1.4)\n",
        "            img = img[size-new_size: size+new_size,\n",
        "                      size-new_size: size+new_size]\n",
        "            y[t] = j+1\n",
        "            t = t+1\n",
        "\n",
        "            # Preprocesar las imágenes según el color_mode (gray, red, green, blue)\n",
        "            if color_mode == 'gray':\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            elif color_mode == 'red':\n",
        "                img = img[:, :, 0]\n",
        "            elif color_mode == 'green':\n",
        "                img = img[:, :, 1]\n",
        "            elif color_mode == 'blue':\n",
        "                img = img[:, :, 2]\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid color mode: {color_mode}\")\n",
        "\n",
        "            # Extraer características según el feature_type\n",
        "            if feature_type == 'lbp':\n",
        "                # Aplicar LBP a cada imagen\n",
        "                features[t:, ] = lbp(img, hdiv=LBP_HDIV, vdiv=LBP_VDIV)\n",
        "\n",
        "            elif feature_type == 'haralick':\n",
        "                # Aplicar características de textura Haralick a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Haralick\n",
        "                features[t:, ] = haralick(img, distance=HAR_DISTANCE,)\n",
        "\n",
        "            elif feature_type == 'gabor':\n",
        "                # Aplicar filtro de Gabor a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Gabor\n",
        "                features[t:, ] = gabor(\n",
        "                    img, rotations=GAB_ROTATIONS, dilations=GAB_DILATATIONS)\n",
        "\n",
        "            elif feature_type == 'hog':\n",
        "                # Aplicar HOG a cada imagen\n",
        "                features[t:, ] = hog(img, orientations=HOG_ORIENTATIONS, pixels_per_cell=(\n",
        "                    img.shape[0], img.shape[1]), cells_per_block=(1, 1))\n",
        "\n",
        "            elif feature_type == 'zernike':\n",
        "                # Aplicar momentos de Zernike a cada imagen\n",
        "                # Implementa tu propia función para la extracción de características Zernike\n",
        "                features[t:, ] = zernike_moments(img, radius=ZER_RADIUS, degree=ZER_DEGREE)\n",
        "\n",
        "            elif feature_type == 'glcm':\n",
        "                img_uint = img.astype(np.uint8)\n",
        "                # Aplicar GLCM (Matriz de co-ocurrencia de niveles de gris) a cada imagen\n",
        "                glcm = graycomatrix(img_uint, [GLCM_DISTANCES], [GLCM_ANGLES], levels=GLCM_LEVELS)\n",
        "                contrast = graycoprops(glcm, 'contrast')\n",
        "                # Compute desired GLCM properties (e.g., contrast, energy, correlation, etc.)\n",
        "                features[t:, ] = np.concatenate(contrast)\n",
        "\n",
        "            elif feature_type == 'daisy':\n",
        "                # Aplicar Daisy a cada imagen\n",
        "                features[t:, ] = daisy(img, step=DAISY_STEP, radius=DAISY_RADIUS, rings=DAISY_RINGS,\n",
        "                                    histograms=DAISY_HISTOGRAMS, orientations=DAISY_ORIENTATIONS).flatten()\n",
        "\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid feature_type: {feature_type}\")\n",
        "\n",
        "        features = np.array(features)\n",
        "\n",
        "    # Devolver las características extraídas y las etiquetas\n",
        "    return features, y\n",
        "\n",
        "\n",
        "def load_features(color, set, function):\n",
        "    # !wget https://www.dropbox.com/caracteristicas.npz?dl=0\n",
        "    # !mv caracteristicas.npz?dl=0 caracteristicas.npz\n",
        "\n",
        "    loaded_caracteristicas = np.load('caracteristicas.npz')\n",
        "    y = loaded_caracteristicas['y']\n",
        "    pass\n",
        "\n",
        "\n",
        "def select_features(x, y, algorithm):\n",
        "    if algorithm == 'SFS':\n",
        "        # SFS: Sequential Feature Selection\n",
        "        selector = sfs(x, y, n_features=10)\n",
        "    elif algorithm == 'PCA':\n",
        "        # PCA: Principal Component Analysis\n",
        "        selector = PCA(n_components=10)\n",
        "    # elif algorithm == 'Fisher':\n",
        "    #     # Fisher Score\n",
        "    #     selector = SelectKBest(score_func=fisher_score, k=10)\n",
        "    elif algorithm == 'RFE':\n",
        "        # Recursive Feature Elimination\n",
        "        estimator = None  # Ajustar\n",
        "        selector = RFE(estimator, n_features_to_select=10)\n",
        "    elif algorithm == 'ICA':\n",
        "        # ICA: Independent Component Analysis\n",
        "        selector = FastICA(n_components=10)\n",
        "    # elif algorithm == 'LFDA':\n",
        "    #     # LFDA: Local Feature Analysis\n",
        "    #     selector = LocalFeatureAnalysis(n_features_to_select=10)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid algorithm: {algorithm}\")\n",
        "\n",
        "    X_selected = selector.fit_transform(x, y)\n",
        "\n",
        "    return X_selected.astype(int)\n",
        "\n",
        "\n",
        "def load_selected_features(algorithm):\n",
        "    pass\n",
        "\n",
        "\n",
        "def load_classifier(classifier):\n",
        "    if classifier == 'knn':\n",
        "        return KNeighborsClassifier()\n",
        "    elif classifier == 'lda':\n",
        "        return LinearDiscriminantAnalysis()\n",
        "    elif classifier == 'qda':\n",
        "        return QuadraticDiscriminantAnalysis()\n",
        "    elif classifier == 'árboles de decisión':\n",
        "        return DecisionTreeClassifier()\n",
        "    elif classifier == 'random forest':\n",
        "        return RandomForestClassifier()\n",
        "    elif classifier == 'svm lineal':\n",
        "        return SVC(kernel='linear')\n",
        "    elif classifier == 'svm rbf':\n",
        "        return SVC(kernel='rbf')\n",
        "    elif classifier == 'redes neuronales':\n",
        "        return MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000)\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid classifier: {classifier}\")\n",
        "\n",
        "\n",
        "def load_trained_classifier():\n",
        "    pass\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6grN-iWqDGy1"
      },
      "source": [
        "### Cargar imagenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5gBOG_ia46U",
        "outputId": "16b6a2b4-0094-4a60-dcfa-5485fe8c41b5"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/s4opefjionbdbab/G00.zip\n",
        "!unzip -qq G00.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDobx-xnGYkm"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/zur2wxzcce4qlgf/G01.zip\n",
        "!unzip -qq G01.zip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0RIDrv8TabcL"
      },
      "source": [
        "## Extracción de caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNdYh_yVabcL"
      },
      "outputs": [],
      "source": [
        "# Define the extraction models and color modes\n",
        "extraction_models = [\"lbp\", \"hog\", \"haralick\", \"gabor\", \"glcm\", \"zernike\", \"daisy\"]\n",
        "color_modes = [\"gray\", \"red\", \"green\", \"blue\"]\n",
        "\n",
        "# Create the \"features\" folder if it doesn't exist\n",
        "if not os.path.exists(\"features\"):\n",
        "    os.makedirs(\"features\")\n",
        "\n",
        "# Iterate over extraction models and color modes\n",
        "for model in extraction_models:\n",
        "    for color_mode in color_modes:\n",
        "        # Extract features\n",
        "        (X_train, y_train) = extract_features(color_mode, \"train\", model)\n",
        "        (X_test, y_test) = extract_features(color_mode, \"test\", model)\n",
        "\n",
        "        # Save features to files\n",
        "        train_filename = f\"features/X_train_{model}_{color_mode}.npy\"\n",
        "        test_filename = f\"features/X_test_{model}_{color_mode}.npy\"\n",
        "\n",
        "        np.save(train_filename, X_train)\n",
        "        np.save(test_filename, X_test)\n",
        "\n",
        "        print(f\"Features saved for {model} - {color_mode}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWOs66SSCFq_"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aYab7JhKabcM"
      },
      "source": [
        "### Guardar en un archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCZBNf0pabcN"
      },
      "outputs": [],
      "source": [
        "np.savez('caracteristicas.npz', y=ytrain)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H5-sRdm3abcN"
      },
      "source": [
        "## Selección de caracteristicas"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p1ijFqTpabcO"
      },
      "source": [
        "Descargar caracteristicas desde el archivo y cargarlas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QISKp5OAabcO"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F1AQ1JMrabcO"
      },
      "source": [
        "Preprocesamiento de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4dbDyRpabcO"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W0C9qJFqabcP"
      },
      "source": [
        "Seleccionar caracteristicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-07V7G-abcP",
        "outputId": "f7fe9ab4-5ccf-466c-f74e-081b523d5ba0"
      },
      "outputs": [],
      "source": [
        "X1 = np.concatenate((X_train_lbp_gray,X_train_lbp_red),axis=1)\n",
        "X2 = np.concatenate((X_test_lbp_gray ,X_test_lbp_red),axis=1)\n",
        "sel = select_features(X1,ytrain,algorithm='PCA')\n",
        "X1_sel = X1[:,sel]\n",
        "X2_sel = X2[:,sel]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn-RlV5WabcP"
      },
      "source": [
        "guardar caracteristicas seleccionadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eIuIHPGabcP"
      },
      "outputs": [],
      "source": [
        "np.savez('caracteristicas_seleccionadas.npz', y=y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f_y248SgabcP"
      },
      "source": [
        "## Clasificación"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1vq1gxv4abcP"
      },
      "source": [
        "descargar caracteristicas seleccionadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvXuDYyaabcQ"
      },
      "outputs": [],
      "source": [
        "# !wget https://www.dropbox.com/caracteristicas_seleccionadas.npz?dl=0\n",
        "# !mv caracteristicas.npz?dl=0 caracteristicas_seleccionadas.npz\n",
        "\n",
        "loaded_caracteristicas = np.load('caracteristicas_seleccionadas.npz')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K22_cA1vabcQ"
      },
      "source": [
        "clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50l015sCabcQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "58_8ANIKabcQ"
      },
      "source": [
        "### Ensamble de clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO29jXRHabcR"
      },
      "outputs": [],
      "source": [
        "def majority_voting_ensemble(models, X_test):\n",
        "    predictions = np.array([model.predict(X_test) for model in models])\n",
        "    majority_vote = mode(predictions, axis=0)\n",
        "    return majority_vote.mode.flatten()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TjLhuqazabcR"
      },
      "source": [
        "## MODELO 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "at7D1MayabcR"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbNN5vsEabcR"
      },
      "outputs": [],
      "source": [
        "# Índices de las imágenes del grupo 0\n",
        "train_indices = np.repeat(np.arange(90), 8)  # Índices para entrenamiento (repetidos 8 veces)\n",
        "test_indices = np.repeat(np.arange(90), 4)   # Índices para prueba (repetidos 4 veces)\n",
        "\n",
        "X_train_group0 = X1_sel[train_indices]\n",
        "y_train_group0 = ytrain[train_indices]\n",
        "X_test_group0 = X2_sel[test_indices]\n",
        "y_test_group0 = ytrain[test_indices]\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en entrenamiento y prueba (Hold Out)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_group0, y_train_group0, test_size=4, random_state=42)\n",
        "\n",
        "models = [load_classifier('knn'), load_classifier('lda'), load_classifier('qda'),\n",
        "          load_classifier('árboles de decisión'), load_classifier('random forest'),\n",
        "          load_classifier('svm lineal'), load_classifier('svm rbf'),\n",
        "          load_classifier('redes neuronales')]\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Iterar sobre diferentes modelos y encontrar el que maximice la precisión\n",
        "for model in models:\n",
        "    # Entrenar el modelo con el conjunto de entrenamiento\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predecir las etiquetas para el conjunto de prueba\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calcular la precisión del modelo\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = model\n",
        "\n",
        "# Reentrenar el mejor modelo con todas las imágenes de grupo 0\n",
        "best_model.fit(X_train_group0, y_train_group0)\n",
        "\n",
        "# Entregar el mejor modelo encontrado\n",
        "entregable_modelo_1 = best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_OMTo9CabcR"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4S7unylpabcS"
      },
      "source": [
        "## MODELO 2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XnwyRdKQabcS"
      },
      "source": [
        "descripción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC4ysEONabcS"
      },
      "outputs": [],
      "source": [
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Iterar sobre diferentes modelos y encontrar el que maximice la precisión en cross-val\n",
        "for model in models:\n",
        "    # Realizar cross-val con 4 folds en las imágenes de grupo 0\n",
        "    scores = cross_val_score(model, X_train_group0, y_train_group0, cv=4)\n",
        "\n",
        "    # Calcular la precisión promedio en cross-val\n",
        "    accuracy = scores.mean()\n",
        "\n",
        "    # Actualizar el mejor modelo si se encuentra uno con una precisión mayor\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = model\n",
        "\n",
        "# Reentrenar el mejor modelo con todas las imágenes de grupo 0\n",
        "best_model.fit(X_train_group0, y_train_group0)\n",
        "\n",
        "# Entregar el mejor modelo encontrado\n",
        "entregable_modelo_2 = best_model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
